# Taming Vision-Language Models for Medical Image Analysis: A Comprehensive Review

## The summary of natural and medical VLMs which are utilzed in medical image analysis tasks.
| Index | Model Names  | Paper Names  | Natural\Medical    | Paper Link       |
|:----:|:----------|:----------|:-------------------------|:-----------|
| 1    | VL-BERT| VL-BERT: Pre-training of Generic Visual-Linguistic Representations      | Natural       |[PDF](https://arxiv.org/pdf/1908.08530)  |
| 2    |CLIP| Learning Transferable Visual Models From Natural Language Supervision      | Natural       |[PDF](https://proceedings.mlr.press/v139/radford21a/radford21a.pdf)  |
| 3    | GLIDE| GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models      | Natural       |[PDF](https://arxiv.org/pdf/2112.10741)  |
| 4    | BLIP| BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation      | Natural       |[PDF](https://proceedings.mlr.press/v162/li22n/li22n.pdf)  |
| 5    | GLIP| Grounded Language-Image Pre-training      | Natural       |[PDF](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Grounded_Language-Image_Pre-Training_CVPR_2022_paper.pdf)  |
| 6    | Stable Diffusion| High-resolution image synthesis with latent diffusion models      | Natural       |[PDF](https://openaccess.thecvf.com/content/CVPR2022/papers/Rombach_High-Resolution_Image_Synthesis_With_Latent_Diffusion_Models_CVPR_2022_paper.pdf)  |
| 7    | ALBEF| Align before Fuse: Vision and Language Representation Learning with Momentum Distillation      | Natural       |[PDF](https://proceedings.neurips.cc/paper_files/paper/2021/file/505259756244493872b7709a8a01b536-Paper.pdf)  |
| 8    |BLIP-2| BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models      | Natural       |[PDF](https://proceedings.mlr.press/v202/li23q/li23q.pdf)  |
| 9    | Caption Anything| Caption anything: Interactive image description with diverse multimodal controls      | Natural       |[PDF](https://arxiv.org/pdf/2305.02677)  |
| 10    | DALL·E 3| Improving Image Generation with Better Captions      | Natural       |[PDF](https://cdn.openai.com/papers/dall-e-3.pdf)  |
| 11    | Dreamlike Photoreal| -      | Natural       |- |
| 12    | EVA-CLIP| EVA-CLIP: Improved Training Techniques for CLIP at Scale      | Natural       |[PDF](https://arxiv.org/pdf/2303.15389)  |
| 13    | Gemini 1.0| Gemini: A Family of Highly Capable Multimodal Models      | Natural       |[PDF](https://arxiv.org/pdf/2312.11805)  |
| 14    | Grounding DINO| Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detection      | Natural       |[PDF](https://arxiv.org/pdf/2303.05499) |
| 15    |MiniGPT-4| MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models      | Natural       |[PDF](https://arxiv.org/pdf/2304.10592)  |
| 16    | MiniGPT-v2| MiniGPT-v2: large language model as a unified interface for vision-language multi-task learning      | Natural       |[PDF](https://arxiv.org/pdf/2310.09478)  |
| 17    | SAM| Segment Anything      | Natural       |[PDF](https://openaccess.thecvf.com/content/ICCV2023/papers/Kirillov_Segment_Anything_ICCV_2023_paper.pdf)  |
| 18    | SAT| One Model to Rule them All: Towards Universal Segmentation for Medical Images with Text Prompts      | Natural       |[PDF](https://arxiv.org/pdf/2312.17183)  |
| 19    | Vita-CLIP| Vita-CLIP: Video and text adaptive CLIP via Multimodal Prompting      | Natural       |[PDF](https://openaccess.thecvf.com/content/CVPR2023/papers/Wasim_Vita-CLIP_Video_and_Text_Adaptive_CLIP_via_Multimodal_Prompting_CVPR_2023_paper.pdf)  |
| 20    | Chexagent| A Vision-Language Foundation Model to Enhance Efficiency of Chest X-ray Interpretation      | Natural       |[PDF](https://arxiv.org/pdf/2401.12208)  |
| 21    | Claude 3 Opus| -      | Natural       |-  |
| 22    | Gemini 1.5 Pro| Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context      | Natural       |[PDF](https://arxiv.org/pdf/2403.05530)  |
| 23    | GPT 4V| -      | Natural       |-  |
| 24    | GPT 4 Turbo| Gpt-4 technical report      | Natural       |[PDF](https://arxiv.org/pdf/2303.08774)  |
| 25    | GPT 4o| Gpt-4o system card      | Natural       |[PDF](https://arxiv.org/pdf/2410.21276?)  |
| 26    | LLaMA 3| The Llama 3 Herd of Models      | Natural       |[PDF](https://arxiv.org/pdf/2407.21783)  |
| 27    | Clinical-BERT| Clinical-BERT: Vision-Language Pre-training for Radiograph Diagnosis and Reports Generation      | Medical       |[PDF](https://ojs.aaai.org/index.php/AAAI/article/view/20204/19963)  |
| 28    | MedCLIP| MedCLIP: Contrastive Learning from Unpaired Medical Images and Text      | Medical       |[PDF](https://pmc.ncbi.nlm.nih.gov/articles/PMC11323634/pdf/nihms-2012083.pdf)  |
| 29    | BiomedCLIP|BiomedCLIP: a multimodal biomedical foundation model pretrained from fifteen million scientific image-text pairs      | Medical       |[PDF](https://arxiv.org/pdf/2303.00915)  |
| 30    | BioViL| Learning to Exploit Temporal Structure for Biomedical Vision-Language Processing      | Medical       |[PDF](https://openaccess.thecvf.com/content/CVPR2023/papers/Bannur_Learning_To_Exploit_Temporal_Structure_for_Biomedical_Vision-Language_Processing_CVPR_2023_paper.pdf)  |
| 31    | CXR-CLIP| CXR-CLIP: Toward Large Scale Chest X-ray Language-Image Pre-training      | Medical       |[PDF](https://arxiv.org/pdf/2310.13292)  |
| 32    |FLAIR| A Foundation Language-Image Model of the Retina (FLAIR): Encoding Expert Knowledge in Text Supervision      | Medical       |[PDF](https://pdf.sciencedirectassets.com/272154/1-s2.0-S1361841524X00079/1-s2.0-S1361841524002822/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEBAaCXVzLWVhc3QtMSJGMEQCIBRfR5e7VIKC0di1aaYtnC6tvGpg4BdAyIbQ6S1mNkrwAiApdlqoiQOxLhiiYz0%2BqBKfqNXHOOn%2FLeXB4mG1rym%2Bwiq8BQiJ%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAUaDDA1OTAwMzU0Njg2NSIMsUsxUEIQ2fksccqHKpAF1aIZ9rXktwjjarP7yRmPmlbHC7HVG4m8sET91UbVt7WQMbo5VhXiXedSi5uJpseFnqBHq1KLoiSRTPtyoucukTYLKUnR82CZOiu%2B7sQQBZeTG%2BnTHT538lcPw6QtJ2Cfpx%2BVuP7EydGp660pfJd7hUY5C7SnFKgXNGVrf4f4D89hAunxGOb3GjZYZL1X5jx3wFwj0Fa9nOYuY2hA%2FfoqXnKTxpdOvoOs6Ya7wETBKo1Ft65Km3pBTS30GX1uNJK3FtYB1V3QM3i7Us5DazqoZHnS57LCjCBmPf9tOX%2F7hWyExw7oxi6wQCwU4%2FIncXNkNFWqvPF7%2BVBKyWgRW2LPEuWHnFz4HrePDo5PJ7tPH2VjyVm%2F99zSFANVET7YW4%2BK%2FbHzTCYEvko1aO5hjUx4LahQ91nA%2FRB6TaridfwlsQoYfc5lT%2FiUSi8m1eiKt%2B5IzHUZMEFWVFkxONnTT3mDCWUVEo%2F19S27h8QElWIXm5XTpUJpRoQZ6craRiBf0ZDnVR0bOazt7RgzZvs8gUUatBHjszn2DrGNDMEDzi%2BxBTm3bBbZ59SSHifGLgXi8TJMgevthC9MQNkOJiV6HYaU9onJvkCpzVUXB5ggEMx8dchthcRquUFbwinNm03epRY1QGFx%2FaH5xeHW%2F%2B1ZO799bxKXMz2Qhpzn%2BDRwybTH2yDTBrsMoUHPaxyGWlQKoW2I1NFXu1hAyP7EPZMynYjHauIa0AT%2FypQOZ9S5rbW0OTGLP6dosgCKIJzllJhf2YWXaDEd1qjeiESEAfMKjpF44%2B6cEHqnfIPiNWOBd1EGcBoFr5q7ajtJ0ByQ9BDNnz7XkqSAm1Upv0tPA7YhkwX1bc0H%2FL5eUHsdwe7TLDISF%2F4w9MjYvwY6sgEplNYS2JaV1RCdjqMGQ8WreDFXscPj41%2FlwrY4IYyaLm16A%2BsNjJU0oSutzsChtrixn5BiynY%2B3QVGtMLM1r3cLnMZgUVzMsxTI58IU6WqP1N%2BnGAQ%2FrDyalL%2FCIVphZ7YAEW9ld2RT922aoOHgz%2BQlY5OmQIL43lec9n%2BlXlT3CkUzfvDdOnmCEoGzYuL2XB98D8vCZtSjSiQ5miKQG0btJj0ZTed%2Fu7YDSmOVzczTtfl&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20250409T081221Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTYQ7UEX4YT%2F20250409%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=b31d1c4ce03c5a0e65d9acbbb4ba3e02e1f4e8cb74135ecbe1c05c1f82e27ab6&hash=126ff7aa37c9aba4349e729aa2852e0bce9c260cfcd682dd4b6be08b541037c3&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S1361841524002822&tid=spdf-1ab78eed-e47c-41c4-bd24-bf008c8101d0&sid=6472ce05872ad34ab77a4da572218302f48dgxrqa&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&rh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=120d5956055b5f5b050654&rr=92d889fa3a448541&cc=hk&kca=eyJrZXkiOiJKOGorRnA4Tm13VGNqZjIwUmt6ajBDa1NndjdFNzczeGlzenRlbUVQenpiOC9IR3ZIQWFWU0p1aURGS3lMdjVBQXBrbXJaVmEveG8zKy9uUWFDNFlvQXMvdk1iSHY4WncrYmhFaklmOGVQQkh0MWRUVkhOWWdZM2ppV3V0L2xpd2ZMZWdHa1VYZy9TUWZhQlBRMzl4M3owQXFHSE0vS0pzVE14NmRDaTVaZ0hucGQ4ZSIsIml2IjoiZjhhMTk0MjkxZjVhMzFiZmRmYjQxOWNiMDQ0Yjg1NzIifQ==_1744186346729)  |
| 33    | KAD| Knowledge-enhanced visual-language pre-training on chest radiology images      | Medical       |[PDF](https://www.nature.com/articles/s41467-023-40260-7.pdf)  |
| 34    | LLaVA-Med| LLaVA-Med: Training a Large Language-and-Vision Assistant for Biomedicine in One Day      | Medical       |[PDF](https://proceedings.neurips.cc/paper_files/paper/2023/file/5abcdf8ecdcacba028c6662789194572-Paper-Datasets_and_Benchmarks.pdf)  |
| 35    | MedKLIP| MedKLIP: Medical Knowledge Enhanced Language-Image Pre-Training for X-ray Diagnosis      | Medical       |[PDF](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_MedKLIP_Medical_Knowledge_Enhanced_Language-Image_Pre-Training_for_X-ray_Diagnosis_ICCV_2023_paper.pdf)  |
| 36    | M-flag| M-FLAG: Medical Vision-Language Pre-training with Frozen Language Models and Latent Space Geometry Optimization      | Medical       |[PDF](https://arxiv.org/pdf/2307.08347)  |
| 37    | PMC-CLIP| PMC-CLIP: Contrastive Language-Image Pre-training using Biomedical Documents      | Medical       |[PDF](https://arxiv.org/pdf/2303.07240)  |
| 38    |PubMedCLIP| PubMedCLIP: How Much Does CLIP Benefit Visual Question Answering in the Medical Domain?      | Medical       |[PDF](https://aclanthology.org/2023.findings-eacl.88.pdf)  |
| 39    | Qilin-Med-VL| Qilin-Med-VL: Towards Chinese Large Vision-Language Model for General Healthcare      | Medical       |[PDF](https://arxiv.org/pdf/2310.17956)  |
| 40    | Ret-CLIP|RET-CLIP: A Retinal Image Foundation Model Pre-trained with Clinical Diagnostic Reports      | Medical       |[PDF](https://arxiv.org/pdf/2405.14137)  |
| 41    | BioMedLM| BioMedLM: A 2.7B Parameter Language Model Trained On Biomedical Text      | Medical       |[PDF](https://arxiv.org/pdf/2403.18421)  |
| 42    |CT-CLIP| Developing Generalist Foundation Models from a Multimodal Dataset for 3D Computed Tomography      | Medical       |[PDF](https://arxiv.org/pdf/2403.17834)  |
| 43    | Maco| Enhancing representation in radiography-reports foundation model: a granular alignment algorithm using masked contrastive learning      | Medical       |[PDF](https://www.nature.com/articles/s41467-024-51749-0.pdf)  |
| 44    | Medical X-VL| Self-supervised multi-modal training from uncurated images and reports enables monitoring AI in radiology      | Medical       |[PDF](https://pdf.sciencedirectassets.com/272154/1-s2.0-S1361841523X00073/1-s2.0-S1361841523002815/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEBAaCXVzLWVhc3QtMSJHMEUCIC3N0lwdWRhQDjL5jb1tf6uxNnNhAkzMMcx7Yy24D20XAiEAoThmKxs6EBhGIErYE3KoEhSiCMMVDTvsUSKR66xRS%2FEqvAUIif%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAFGgwwNTkwMDM1NDY4NjUiDJHdjTZV0t2TPi3nZiqQBXquKQy5EKEKEvrGVpR4euEHExWeYvms1TM2CQAr4CrI%2Fje9FYdBBSua6f4gw31UzPPxMB1i5A3RlUBg8ebPCfCfDNJ8AvxxyoVNdqU9BPalM7BIo5ey%2FqB1MEKilWVwrxHjcgAvNoKNyTjlaQs4XmEomSA6gAXRsmhWN8I3G%2BbYl8U7oL48JatKZTHNvkbU8zOlBwcenZHvG%2F4DmuPrsszzs%2BECcBnTfegWeT7EOvJ5oVng2%2B2zBQUwNrPR0HF%2FYtur0IjOqEAHxFYALS5w6AttN%2FUNuxu0017G7g7i1VR8Bc8OBOLP889enX%2FMx0e%2ByDg8qW9hCv4C0Kd7fTFaXsc7319pxaJikVnAMHGOf1pZFCnmyKI0n%2F5fHxTxdSb0rUuHJ04eYxpejrGweuvDBVn%2BUU9dYD2phR5%2FAtXvNbWQN%2Fhzbd0Ipa7Ae%2F1A7ae8%2FLNmiYHIHaaIiW7XhlY0zxxkSo%2Fvl5xWJbnlKkj8d4UaWOUKo2vQ5pnktpDCNhcCPKUG3%2BQyoTmxahqGIZUa720SN2dOK91y5TiV%2BUiRL26b9duObic2EJ%2BkPtpQzKKDvH8AJb%2B8%2FQ3vo5tA7PvpISee6deE3FG%2FlbhcbueXyC4pJg%2Bhxtpdic7FiV6t8BLT6a2oA%2FZ%2B6U2AK65Ehu4yzTDm4Peuw0%2FExs%2Bm%2BqIFmUNttIGXTLhC1rg6STMQV5pSeBfJyEV1YbjhuaI3ynTc1hFGF7KI%2B3vQYBll5YbXlNzDx4Yef7hcq0ib89v2g18vBK8Hcl3h0KHWx313bzWUdUEZCLxLhmUWobPZe4sB4ejqnZY8fLI9p1YFTRvkQoCi3xTNp1%2BcnKgKWMpYEpTqudVxLFyEpzhwzzHfRmlJd9kJMPHB2L8GOrEBwn2nt8h6N95CWhNPMv2c%2FqAGOiwJoelT0Wq1naGZwo7pA8l8n6QmUPE5Au45lixxlhM%2BXwqv05B%2Ftk4h3FvH4fQ%2Fm6oyH%2B%2BzGxbP6XOOmaW%2FlUJNnn9htlXAonY29ZwsnVAgjS3vr%2FHH73NxMGbJWQpKbtvcfHkvs27%2F5%2Bobt%2Bd%2BYvKlDJ8GBjUlTHJo9Zjmi%2FTHpcLhfsU0UfFGGN7Y9Rto%2BL8H7gGWHVYE21TloxAj&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20250409T082514Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTY7HQT7NEQ%2F20250409%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=73ddc4b2f47c5e850f7a23755fb0d64f32018e7f70bfaa7ae70ca6e14ccf4231&hash=bebc4805ae9fe726a754599d0d702205fc49f0b7f0f925ff4f9d50135805f76e&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S1361841523002815&tid=spdf-7163bf0a-cff2-496c-9c0f-352fd7db1d0e&sid=6472ce05872ad34ab77a4da572218302f48dgxrqa&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&rh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=120d5956055b5e01075001&rr=92d89cd7f8f80445&cc=hk)  |
| 45    | MPMA| Multi-Task Paired Masking With Alignment Modeling for Medical Vision-Language Pre-Training      | Medical       |[PDF](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10288259)  |
| 46    | QFT| Design as Desired: Utilizing Visual Question Answering for Multimodal Pre-training      | Medical       |[PDF](https://arxiv.org/pdf/2404.00226)  |
| 47    | Unichest| UniChest: Conquer-and-Divide Pre-Training for Multi-Source Chest X-Ray Classification      | Medical       |[PDF](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10478603)  |
| 48    |UniMed-CLIP| UniMed-CLIP: Towards a Unified Image-Text Pretraining Paradigm for Diverse Medical Imaging Modalities      | Medical       |[PDF](https://arxiv.org/pdf/2412.10372)  |


## Medical Report Generation
| Index | Paper Names  | PDF Link       |
|:----:|:----------|:-----------|
| 1    | Automatic image and text-based description for colorectal polyps using BASIC classification      |[PDF](https://pdf.sciencedirectassets.com/271219/1-s2.0-S0933365721X00115/1-s2.0-S0933365721001718/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEBEaCXVzLWVhc3QtMSJGMEQCIESGdq%2FDa9rvL5PYnG4fcNpkngfzmXtMFE5HQ%2F4DWg1vAiBpLj%2Fsw4%2FbQJxr5XNF6pibt4rMMOOReW2fayGtAzm2XSq8BQiK%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAUaDDA1OTAwMzU0Njg2NSIMRAJeaPBTcxXD4HnvKpAF968bFQ28jTyyramY34Upapy5ZPCSQPVnquhEGoEjpypZ4%2F%2F0lwrSs8SH7Aa5GDr77d1CN%2FMY4SCBI4WXNhm4VJuAClme0qwsT5dZq0JrLQk4ULVjgfUKs76fKjnxNdgvULZ3P2SRpm3JJUUcCxgb9usK2NuJlQYrk5NZo3jM4WcCvnHvTG6MeQqdVPJ%2FfAjw8kfhzPcBXuObE2jo74xD0B4DjtWQbpWZ3WJjgDlWQBkTAJASGzSenq%2FgFJXSjWB1pPoE6b91SFVz0S6I9p356FmnGnq%2Bds53LFy2AhHVRK4IR0AMdyEU%2FC9tCoVhZHKl63Hu%2BKNtzhAsHTvieA1orTxZL7FHKiRMdXqj5dV6qzAfBv6qPAt%2FRUoTmoISfT%2Bjv8m2DhGKpk78Ta1eaMGC5sQ0gdkUfF7wYj6DE5swGegfnmta2iNQkxeWUI073bh%2BL2QMx8vUbNWQfRZEi31pzIWbTOyhtEjDSQZut6DOw5cBshXvfPOmOvTy70eYiltPfRvTJxhATtNhuDs%2F0QN3JfoEyjDbJckbQ%2B4FxO0IgFDd%2FK8OUq%2FuXkqMzvhQ3D%2BSB%2BPb5aJDh6sTjAt2k%2BhUla2wmxS7wxqNBle1Kq6OjkjNtX83pZ%2FKckhkytN8lLKAlFNodbiX7txKIrfAHRZ5Iiu9SQVa%2F0TBdVWTjkQkapyn1sQshR8xS8gELBQwiDdfU2%2BnOcSay5RMgQS8sSrXMarkn9ZP4KVZI1ggJ5MGGhhH3XVSIVmUALRXYyw2e2x36j%2Fqy2nXj1C7JxVgqooC7kxDa%2FU587IDHCobzNRxzRKBH8UN%2FxAUUhf7VWNQ1Xk2Y6Gt1RU3i6dUsCogm%2BEv0abIkFqtWF4ye4FA%2F%2F9Mgs8w5u7YvwY6sgGaXQrXSJunAN%2FM1mYYmIkxgqw1XmUWsmp4XoT%2FVY4f8ec8gPeaQuFaEbqtaDF5MQI7gyrBW8yoFNQbf0xknoBOBwaQokaNJVq7oRl7t%2BOcA0cMGVd9IJxkeMdPebxZi%2F%2FQoCaM9fOB89jVd8HWQhnlxvSyJmujeq0EywG3z0KFeRl41Y0DSlEE9ymxv3Q9fZCAn6pqhZFMnZefGtErMx5K1ay56bjrxqJYO8WeiTpEtMKM&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20250409T094850Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTY7AQD6ZFH%2F20250409%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=e838f088a3b5967bb888670beebc7a2a9e574b2ececc3bcb098b7939eb96b670&hash=8a1ca1f7005e141f23bdf14c22bcb2f3ddb7d51f6ca0f3105db9f4ea8086d425&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S0933365721001718&tid=spdf-65a3a3b8-1692-4c3d-a866-caf985e0b786&sid=6472ce05872ad34ab77a4da572218302f48dgxrqa&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&rh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=120d5956055a5655570153&rr=92d9174f480e84be&cc=hk)  |
| 2    | Bootstrapping Large Language Models for Radiology Report Generation      |[PDF](https://ojs.aaai.org/index.php/AAAI/article/view/29826/31434)  |
| 3    | Clinical-Grade Multi-organ Pathology Report Generation for Multi-scale Whole Slide Images via a Semantically Guided Medical Text Foundation Model      |[PDF](https://arxiv.org/pdf/2409.15574)  |
| 4    | Continually Tuning a Large Language Model for Multi-domain Radiology Report Generation      |[PDF](https://papers.miccai.org/miccai-2024/paper/0254_paper.pdf)  |
| 5    | Contrastive learning with counterfactual explanations for radiology report generation      |[PDF](https://arxiv.org/pdf/2407.14474?)  |
| 6    | IQAGPT: computed tomography image quality assessment with vision-language and ChatGPT models     |[PDF](https://link.springer.com/content/pdf/10.1186/s42492-024-00171-w.pdf)  |
| 7    | Medical-vlbert: Medical visual language bert for covid-19 ct report generation with alternate learning     |[PDF](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9509365)  |
|8    | Medical Image Description Based on Multimodal Auxiliary Signals and Transformer      |[PDF](https://onlinelibrary.wiley.com/doi/pdf/10.1155/2024/6680546)  |
| 9    | Multimodal image-text matching improves retrieval-based chest x-ray report generation      |[PDF](https://proceedings.mlr.press/v227/jeong24a/jeong24a.pdf)  |
| 10    | Improving Medical Speech-to-Text Accuracy using Vision-Language Pre-training Models     |[PDF](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10372102)  |
| 11    | Kiut: Knowledge-injected u-transformer for radiology report generation      |[PDF](https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_KiUT_Knowledge-Injected_U-Transformer_for_Radiology_Report_Generation_CVPR_2023_paper.pdf)  |
| 12    | Pre-trained multimodal large language model enhances dermatological diagnosis using SkinGPT-4      |[PDF](https://www.nature.com/articles/s41467-024-50043-3.pdf)  |
| 13    | Repsnet: Combining vision with language for automated medical reports     |[PDF](https://arxiv.org/pdf/2209.13171)  |
| 14    | SERPENT-VLM: Self-Refining Radiology Report Generation Using Vision Language Models      |[PDF](https://arxiv.org/pdf/2404.17912)  |
| 15    | Token-Mixer: Bind Image and Text in One Embedding Space for Medical Image Reporting     |[PDF](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10552817)  |
| 16    | Vision-knowledge fusion model for multi-domain medical report generation      |[PDF](https://pdf.sciencedirectassets.com/272144/1-s2.0-S1566253523X00050/1-s2.0-S1566253523001264/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEBIaCXVzLWVhc3QtMSJIMEYCIQDSD%2ByIxH0s6ijHnlJsZVmB%2Fu2AXROZ0Q0To69JiRAmpwIhAKc4uyJrhc7J482%2BzwHXY%2BPHyxbuQljpIuAGggOyAhKXKrsFCIr%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEQBRoMMDU5MDAzNTQ2ODY1Igx8eo%2Bh%2B%2B0p1LaTSXsqjwV84WaJgcoPyneMcmbrGsCCMWeMEXGFW290DQwzncXjcgAtr%2FS9VHeCRPnqXLy8RB1hIr97RMxTK7%2FOI2xGO81KJ5ArLKyPy42l2z%2Fkln6IkylbIF%2BpMbktCyFTiNZMqtydy6eOT%2FzoUyFlScvFVMPKuwe1tE0Z1WBZq0gptAj%2B%2BXkYJkmKmC9Zz6WkPp9gYXZ%2FtjALUattC0b69nfDv7vqhgtfzyZXBjJXvW2TjCuYtd%2BcUTPXVJAEtKB2%2Fd040dz8NMNKSmA9QjEfJBXSJrDu94ah%2F%2BWNZW03s8%2BOipnGrsfJCOILn%2FxxLZEuNX5A1JtV%2BkhqHKZQkaa86cxegr%2BHX%2Fe6YapxzPNt21q%2BpUYk8wFu8aBh9nhwr9f1O%2BQbb2zdJ2gb9jfY69XEFEOEtLoag%2Fo5trUiPvxHY7uKMKqlA%2BJlh%2BnbcwaqNkSJMnHKXZbkoCBkelpzz4w6FlUrv4GwX6gtIGM9zcCY19k%2BPQeRCX1mBOhBepLqR812M3qEjvAV8ny79K5THytcm%2Bl8J4qLvobCQmOHWRXXB%2BQhMNudcOgWOkKjN7DIus89IOPVAWgjfC%2FA3eW96n0Zt29755TjmerUchBhSP6vb5YF6ZdO%2BnFqcpXEHFxBTw6rzF%2FlYGgJWNmYFmrWRcxVsGiyvsEQ38dl3o1XnCvV0iYBccvGL2iUbrOvOvWu4%2B7Cr2BJrNldh96jOOp75Fuz18ybmcmbc6jD6VrIGNnlwPlhwShQuwNTa%2BFBEFiRPrmbmBtUjdwzqLOaMEie1DIOBiStKzA8HmlTI6QXp4Oqqn5UhtNkYWR0uY1C93lJEybplk%2BPwRTjOvKiUs3ECXNi%2FAKUSQJ%2BYimRi%2B0eMKp9HXCUXP78MNr22L8GOrABrObX7PO%2FcOyBgZjYv7lhaUiDxp8f81cNRxHvOkpkGuDSNmchdV3%2Fqu9z5grcJtkuCrFNaswu9GnMbFuNEMDQb%2FCQ%2FmS3blZrGXfU81QAlsJQhwXHHhjJECBirzZWbBuVhTaVobfkbC3D24CepmDFTJWwM%2FAIPBRKmb6WebuJGuWxZRlamSx8AEiyVJZgQfnCH9b%2B7zlU5jQByTGxrfnpEDTyverPWh8UvaqrxDm1TCk%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20250409T094817Z&X-Amz-SignedHeaders=host&X-Amz-Expires=299&X-Amz-Credential=ASIAQ3PHCVTYR4UVYR3S%2F20250409%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=4513b70fd854108e3a8b216c060f3adc51f4719cf94efeeb3506e9fc4e53cdfe&hash=f0d654ba525e6700da6645f6f2328cfc0fb992b9a17c6b8dbb22477a1bc0071c&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S1566253523001264&tid=spdf-c5e4a04f-87fd-4807-88ba-92675a888fa1&sid=6472ce05872ad34ab77a4da572218302f48dgxrqa&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&rh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=120d5956055a56545b5656&rr=92d9168119c884be&cc=hk&kca=eyJrZXkiOiJEaTdrWW5tOVdOd2lOUXhyVVN1VzdidmI0RGJpUnVGQXR6QXFFMWNYODdmZjlYNkJiMkUycEVDT2dJZjRDM1JOMlFFVmF4RWtnaDlqWXlMZWEwTDRwZzFCdXZzQ015QjRpVENsUnVnMHc5VEw5YUhHcXlObEkwUnFGaTJKcHUwMGNFZ04wR1FqcEF0a2U0V1dVSFZkOEg1ZmNnMDNiLzZkMDNCWCtQWHVYK2tBOEFjPSIsIml2IjoiNGUzNGQwODAzOGY0MTBkNDcxYzc3MzI2NGZkMDk5MjQifQ==_1744192102808)  |

| 17    | MEPNet: Medical Entity-Balanced Prompting Network for Brain CT Report Generation |[PDF](https://ojs.aaai.org/index.php/AAAI/article/view/34788)  |

| 18    | MedRegion-CT: Region-Focused Multimodal LLM for Comprehensive 3D CT Report Generation |[PDF](https://arxiv.org/abs/2506.23102)  |

| 19    | Large Language Model With Region-Guided  Referring and Grounding for CT  Report Generation |[PDF](https://ieeexplore.ieee.org/abstract/document/10963672/)  |

| 20    | HC-LLM: Historical-Constrained Large Language Models for Radiology Report Generation |[PDF](https://ojs.aaai.org/index.php/AAAI/article/view/32596)  |

| 21    | CXPMRG-Bench: Pre-training and Benchmarking for X-ray Medical Report  Generation on CheXpert Plus Dataset |[PDF](https://openaccess.thecvf.com/content/CVPR2025/html/Wang_CXPMRG-Bench_Pre-training_and_Benchmarking_for_X-ray_Medical_Report_Generation_on_CVPR_2025_paper.html)  |

| 22    | CmEAA : Cross-modal Enhancement and Alignment Adapter for Radiology Report Generation |[PDF](https://aclanthology.org/2025.coling-main.571/)  |









## Medical VQA
| Index | Paper Names  | PDF Link       |
|:----:|:----------|:-----------|
| 1    | 3D-CT-GPT: Generating 3D Radiology Reports through Integration of Large Vision-Language Models      |[PDF](https://arxiv.org/pdf/2409.19330)  |
| 2    | Candidate-Heuristic In-Context Learning: A New Framework for Enhancing Medical Visual Question Answering with LLMs      |[PDF](https://pdf.sciencedirectassets.com/271647/1-s2.0-S0306457324X00035/1-s2.0-S030645732400164X/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEBMaCXVzLWVhc3QtMSJHMEUCIEvDCapOdDypDp5LcPz1TM8fi6BNrNXJAcTmViMEayWNAiEAiDkaQNBvSSxvdpyaQzdkaup%2BpKNtH07pxF8rnrQt7dMqvAUIjP%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAFGgwwNTkwMDM1NDY4NjUiDJgY3yI63mC%2B%2BVlX3iqQBVgyQByoyxEcwG%2B1%2FF0mYxHH9rI3c8cfafC%2FVjeotmmG9Q5U1ZispeyhJztSkg8UGTiRIeuQ%2B%2FGxiSFat2j86T%2B52duhHVQh0axLG95GvozelvG8UW4Ml%2BlZEV69XBC3VLA1UwnlPgayMPVEuiGpgvQdbAdmWblAJRffci3msyme7tUZGdsC61U3GNSNXaENDxI0cMH8tM4NH6g4IaETjX4EmyiMAF3cwwoRXDEV%2BE15XEtDzHGQ2QQvbNLRXbHx45JG3Kcdj5RUox%2FqOUrmOPAdDeyPFkTzAwOFQLj9AfbCnNm%2FQh7c1SB%2FY%2Bljaq8bVmMFjlSBfwYzvOM8jkvPF2cZ5YRX%2BT7dexOSjvmzYvKk%2FlrIPAaLMzPl0BFo8et00p6IcZvAokNdsMWmZ55BQHtDiCtN5wMa6DMiQXg1cJZqMYEO6Pfyij0v%2BmKaE2J2cIv223CNtXROVHHcYNKEtRGkxv97kS6JOKIHvPtFhIi5Xxf6YplzZJUx2SMzDPxUeoUieh8uh9KkKId4N66inVQZKQPotwFTy4EKVsDQH%2BIY9igYTalM0Rlg0RFetL9liU1DwzS2CMIlbMIrf4JQYYbLrd2nxtjpXhR7jsgHAVNa8dqWFNdpuUzMDXGrzuz3ZyhVgvNtFTv231L4%2BvyJmsCWqy0JlZQSTUqseC%2BqmbDl%2FVr%2FrL3YD5kxjv7Pq3v9IeQrcK1eRMOlSrA%2F2EI4hWU21sTHMB4Flh62MGa4IyySj4wOPXzSpXkfK2y6rfpZw7zrQ82aco8L94jsxlwLq0m%2Btc3UbdADiWHm0zpKd7giVATzXa5Pb1LhIw1kb0vxh0Bcno7AcOSz5WekGDnLXqTDtjD9Yu0FG%2B3SIAuHMMQzMOin2b8GOrEB6f08z6YF0GrLlRRMHZM%2BNFgZbufnPj5r3GN566NKZ10IbRLu%2BKvToEhmT9QgthXiwKqeVZl4GYO7v5dU9tS2ZkYp%2FQEkBXyP0MSAfv%2BaquNFtU1b7834pP11xFsq5BPPDV%2FmJCBr%2BvU8QK0RtFNU44Dk1LCGkIDFXTT%2BLTWaZRGJhCpjCFXeCCPzB0CQB6ZGucnG0yBHnJlJDgjtPc9sbKw28nibBHJCi%2BbR3ilr1gJq&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20250409T114406Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTYVFJGWYMO%2F20250409%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=08ae0689df97ee01a3a82be0c3008401aafbdacc3cdd89a53ce23694b51d7737&hash=4c68f0874995d8de569d250465fdba2d7b6740e0c8006aefd511f239283d1edc&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S030645732400164X&tid=spdf-db7e8629-7a82-4d0b-a1b2-f5b6ceadfa51&sid=6472ce05872ad34ab77a4da572218302f48dgxrqa&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&rh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=120d5956055a0452515254&rr=92d9c025386a8582&cc=hk&kca=eyJrZXkiOiI3am8xOWhLYnovc2F3SkVpRldoWmpjWllUM2l3K3c0ZG9RZ2lwR0ZKMWlyZW5NSkhiait0c2NtTjJCMGlmRDhFaEd1aTFNRUVCOS9uRFFNSVEzaHVta3pock5NR1pNM1pvaGJJbTF4RzlIUlQwY3JtajlWOGhFeStmeHJ0TDQyWlFaeHpDZ0V1ZklaeWs1L1BlcXcySHVUdVMzU0ZmOUhJSG1HM3ZJUjBoUXdkTGozMCIsIml2IjoiYTJhMjcxYmJlM2Y0YWMxMTYxNjNjMmY5YWVlMDRiYWUifQ==_1744199051256)  |
| 3    | Debiasing Medical Visual Question Answering via Counterfactual Training      |[PDF](https://link.springer.com/content/pdf/10.1007/978-3-031-43895-0_36.pdf?pdf=inline%20link)  |
| 4    |Deep Fuzzy Multiteacher Distillation Network for Medical Visual Question Answering     |[PDF](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549832)  |
| 5    | DermaVQA: A Multilingual Visual Question Answering Dataset for Dermatology      |[PDF](https://papers.miccai.org/miccai-2024/paper/2444_paper.pdf)  |
| 6    | Diagnostic accuracy of vision-language models on japanese diagnostic radiology, nuclear medicine, and interventional radiology specialty board examinations  |[PDF](https://link.springer.com/content/pdf/10.1007/s11604-024-01633-0.pdf)  |
| 7    | Gpt-4 turbo with vision fails to outperform text-only gpt-4 turbo in the japan diagnostic radiology board examination     |[PDF](https://link.springer.com/content/pdf/10.1007/s11604-024-01561-z.pdf)  |
| 8    | Harnessing the potential of large language models in medical education: promise and pitfalls      |[PDF](https://watermark.silverchair.com/ocad252.pdf?token=AQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAAA3QwggNwBgkqhkiG9w0BBwagggNhMIIDXQIBADCCA1YGCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQMO8PsdoemXjM7ufDnAgEQgIIDJ_Sd2_4NfmXOUtlZkNYtCxmL-tXTIEI62HoooYiwcfBkWEeMvHyiMgLD0ikV3FGUYrKL1OEMJY4vLMPtXWILQL90QssxQeghFI5-5hWNvFQlH2wlL-5IMA956G0GifG4t0iyj83bSXG-Kxp1S3KeCY-tudGrgMIy8VsZQn8FoWhhtAcNZbYsdQzWLe8142QMSc8rZTn3_voQWHm9CJc34KroYR-wPBcMtZo9ATCnCqHE2ZGGMhdhh3EsgiLOqAXieWtA3E0swIGXYbFvMHs36Ru6YPs6qddU1xA8J8PV3WD9r8ulgVjbjXmFqz8hP3hz4XHdDu03mn7rHFX3Bwm3dFwd4BPqozrdEcxiUusJwzNJjjHg_Gg0zcSmoOsHuhqWtzBitWKK9yL2a2ldEAt35IfW-WfWwHmrX6_xFAddm6Nk-f-f_jSm-AJ2nj1ip3aHrpvWnedlfi3KVWJdY338Hccj3BkvWXwXTG7K63DqGl8UDiyGxlxS2BAlYt1l52yXn1DYo-tiCnAauIcB2Y7y9AKCHuT9_xIBCB5_ZoIUibvfB6lyV3WJI6DING9Ce3GZn3japfNCAnZkFiuzHr6yGj6wovIJaCJckkKIjTJVbye6uuE2ssH_En1eQVLmYpQUdEM4y7cXkKxozMDPKNupy25FcieJuPm1CWP1cp7fLG7tSZ8-ePra-GvwqnVMj6hDH13hzWjn08oW6Ma9K7nTS5YYQ-4id79DApmfQAuIIGr3GXGn7j9Em-Np6M9W0mnNl2I_07FaAdbpinxJL_my3QUd0EyW2Z7iSSWGZLYyoXTsi4j2SjwJ6kmujCmVGfvkQ4EnrNog3h2hiCiY0KkDoztWC2HxQnLnD_32bG9VRfFqUeM5klQA_KKsXx2vtSmwnGglPaSD4vtnkWieZG-dzhiklRh78oXnpQggUyyXVWOIiPPYcKiiN6Ry4-goSyAgYHVfIq-Gsbwws77MAXat602bLwPDGaqXzzh6Y-M9vBxM-SdC8g87DoOCLH82LZ1kHOKAwb_aDusffhcq6JDLZYiE2FMsf0fuY0SinL6LUbdaJ1LJVGfOEg)  |
| 9    | Interpretable medical image Visual Question Answering via multi-modal relationship graph learning      |[PDF](https://pdf.sciencedirectassets.com/272154/1-s2.0-S1361841524X00055/1-s2.0-S1361841524002044/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEBMaCXVzLWVhc3QtMSJIMEYCIQCnXXc4IiHdiQ2Gi7p6%2Bvm4AfuLeqspymB%2BkRXNE%2BfCkQIhANPv7OXZbH1Yvq9wxtJRAi0gg3hGTR5b1Zo59HIgbyAiKrwFCIz%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEQBRoMMDU5MDAzNTQ2ODY1IgwZWkNoLYB3icpCILYqkAU9i2UKZ1yo3bAEBlTVmfSdenCY7U12YXL0bPM%2B13pthGMb4l7YCpBBk6V1IDWtekqe2q32ddKDW4nt%2B4F2rVA8U3WfW2mYJ%2B7pDwOQK1k4XUotOvfaPxOWiCZ22qumMNHWPJKxSW2%2BOc%2BiLBVa8jjVBKvyweURu3CEDDiXB1ujMisJ2u7BjIm9DyR%2Bi8q1r1Box4UMYsYWt71mUIFAVVW7I%2BdlBjQMCnIrO%2BvtI7b9CgNvQM5xqMQG2A2kADyMntHuHnTxFlIKuQGk9K5e2lS%2FZGsv07CbNW3OAmjIoGVYUpmGWZWik9eWRcQpjCTR2RGIjr%2F6FUKbWK2L0vWQmm0qPxdz%2BseVyP5t6KjO3szYfiXuIfi007midllfP88839ly%2BEjky9NIySyXTZUydS5gaMzReS%2FgC4FBxZKA%2B7%2Bt9HSj%2BBhgtLE20vCgBdOqHco0c3mblP6%2BWCWJOH368KMqTukP95EMXMNAo0Y21u49DL36IM61qtiCfUFv8teEgxqS5WdK5slohbP1FrP0vOw0VRjjvnbB4h9koaaqTsSYaetW4DB5qPyMg3u2ljLeTSskmniFFOtgGtNwiJWNgP9cDx%2FwBjZueXQoJQl%2Bt%2BDZY9fCsG86EHSyKAownsXJegSOq8RBVH5b9%2Bs1JljSH9eRa9nAByVOxwWlvOQ1YdjEH3qR0u7Qx6kmnYMd%2BS3LIT2NRF6B1Gh9HRskenSiRHp%2BlgUOTjbXQfcG5kIvs9GYWU7Az7c1AGJ3Troqg%2B5Wxq2a4fWZOF%2BSaCVWndU%2BdbVnFan82YDtWjXT3KG9RM7Td%2FLq%2FPaNXE7ybt8tbUyMgPsMPGbSnPmn4l4DzsXF5I%2F9vMzUFwT6kExmVpArlzebpTDiotm%2FBjqwAcJk4rtg8jwUAj6LSI8j7HgTRrD%2BL%2FFtB9HwatEU%2BgB%2FVe2SbwnbxwgmIfmwy%2FUcf9hqY3B6vC6zk4gOuMjMo3y%2BQzA167rnNTAI8vaZ7w%2FmnOq7OYUiBJpz1dIOFSdhVk7ug3JulMSRp1Se2blRcFZbRLZ1Brmp%2FBqEySFrQl0CkyIx%2BqpA0vZhFl%2BuQcuAeD%2B8ZKN88qDGZNuqDIfIQEscwfyXSCQDqMmyS3DfxQPq&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20250409T114932Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTYVWOHQCHO%2F20250409%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=71a1f389ed852eeff5d0b993a055b38f0dba32f8db08307121bbfb8bd7220ba1&hash=f72a5053a203ee709bdf1b9fbe780c7583f4935e09152a27e71939c0f69e68ec&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S1361841524002044&tid=spdf-dce38791-e1df-4def-9d93-bcec132be84e&sid=6472ce05872ad34ab77a4da572218302f48dgxrqa&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&rh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=120d5956055a045a520501&rr=92d9c81bfe378582&cc=hk)  |
| 10    | LLaVA-Med: Training a Large Language-and-Vision Assistant for Biomedicine in One Day      |[PDF](https://proceedings.neurips.cc/paper_files/paper/2023/file/5abcdf8ecdcacba028c6662789194572-Paper-Datasets_and_Benchmarks.pdf)  |
| 11    | Open-Ended Medical Visual Question Answering Through Prefix Tuning of Language Models      |[PDF](https://arxiv.org/pdf/2303.05977)  |
| 12    | Parameter-Efficient Transfer Learning for Medical Visual Question Answering      |[PDF](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10256025)  |
| 13    | PitVQA: Image-Grounded Text Embedding LLM for Visual Question Answering in Pituitary Surgery     |[PDF](https://arxiv.org/pdf/2405.13949)  |
| 14    |  Role of visual information in multimodal large language model performance: an evaluation using the japanese nuclear medicine board examination     |[PDF](https://link.springer.com/content/pdf/10.1007/s12149-024-01992-8.pdf)  |
| 15    | SurgicalGPT: End-to-End Language-Vision GPT for Visual Question Answering in Surgery     |[PDF](https://arxiv.org/pdf/2304.09974)  |
| 16    | Vision-Language Transformer for Interpretable Pathology Visual Question Answering      |[PDF](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9745795)  |
| 17    | ZALM3: Zero-Shot Enhancement of Vision-Language Alignment via In-Context Information in Multi-Turn Multimodal Medical Dialogue     |[PDF](https://arxiv.org/pdf/2409.17610)  |




## Segmentation
| Index | Paper Names  | PDF Link       |
|:----:|:----------|:-----------|
| 1    | ABP: Asymmetric Bilateral Prompting for Text-Guided Medical Image Segmentation      |[PDF](https://papers.miccai.org/miccai-2024/paper/1674_paper.pdf)  |
| 2    | AdaptiveSAM: Towards Efficient Tuning of SAM for Surgical Scene Segmentation      |[PDF](https://arxiv.org/pdf/2308.03726)  |
| 3    | Ariadne’s Thread: Using Text Prompts to Improve Segmentation of Infected Areas from Chest X-ray Images      |[PDF](https://arxiv.org/pdf/2307.03942)  |
| 4    | Bi-VLGM: Bi-Level Class-Severity-Aware Vision-Language Graph Matching for Text Guided Medical Image Segmentation      |[PDF](https://arxiv.org/pdf/2305.12231)  |
| 5    | CausalCLIPSeg: Unlocking CLIP’s PotentialinReferringMedicalImage Segmentation with Causal Intervention      |[PDF](https://papers.miccai.org/miccai-2024/paper/3127_paper.pdf)  |
| 6    | Common Vision-Language Attention for Text-Guided Medical Image Segmentation of Pneumonia      |[PDF](https://papers.miccai.org/miccai-2024/paper/2599_paper.pdf)  |
| 7    | ConTEXTual Net: A Multimodal Vision‑Language Model for Segmentation of Pneumothorax      |[PDF](https://link.springer.com/content/pdf/10.1007/s10278-024-01051-8.pdf)  |
| 8    | Enhancing Label-Efficient Medical Image Segmentation with Text-Guided Diffusion Models      |[PDF](https://arxiv.org/pdf/2407.05323)  |
| 9    | LGA: A Language Guide Adapter for Advancing the SAM Model’s Capabilities in Medical Image Segmentation     |[PDF](https://papers.miccai.org/miccai-2024/paper/3350_paper.pdf)  |
| 10    | LViT: Language Meets Vision Transformer in Medical Image Segmentation      |[PDF](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172039)  |
| 11   | MedCLIP-SAM: Bridging Text and Image Towards Universal Medical Image Segmentation      |[PDF](https://arxiv.org/pdf/2403.20253)  |
| 12    | Multiscale Progressive Text Prompt Network for Medical Image Segmentation      |[PDF](https://pdf.sciencedirectassets.com/271576/1-s2.0-S0097849323X00077/1-s2.0-S0097849323002170/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEBQaCXVzLWVhc3QtMSJGMEQCIAoY0yV2ALfk8R8H7%2BIROYgmMuor%2BD7bugL9r1laRMpwAiA9sgfh5IctthJb%2BACW9mM5rIRcQZB7qtq7N7wR1SQkeSq8BQiN%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAUaDDA1OTAwMzU0Njg2NSIMcKoinbzn6YZ8j6KSKpAF6CiG25HGFy14l8uHWmGMsrHqV9M2nCCASpMfIgXDDtH%2FUXhWwM49UznokS5Vg4X1GfhGxL6cPOi2f5Se4GXI8vXyTYQGIXkPq0BEa8UriQL%2B4I%2BzzFKC3kr4rx0Vk0BaUe3V7Rj4OzMmFWxhLERZW9YliWT5IehRw45e9V7cmsCfad4U8py6VIeAiFuJhG%2FrGL3XLjBThQyYYRYm898mqOuyN11yLBksHTHaorDe24Hj3bc9TjB9gJxZdXbvxO7%2B0FAuXsGm%2FQ7c22Zil%2F2GrQyk410aHJUPj8GExV8R2NmYQXmDirg2hEDXdr7GQuL8bfT%2B3m4QHUyN67MPsJzxVGhvD3mFYHSKXRsN4DonLoiQVVkw26Lb%2FnJFpXXb6dRlDma5SSWxwPYxRGipTTEZZpFZd3BczrYTe41oYNYKVCdPkQEaLeBrIE1TzDDikLavhfXkWuZwIQEHSusFKKlHhuMBH9ny9na3vJN%2F%2F4046VF1IxrnTu%2F7iTxWHWBCOPstndIBIt5JEJWPbyjfI2Y1HOBSO872ekRh4tg423zf2Ea8Bk01PXLXV6pAbL35O4T%2F%2F%2FnqK1t36FunMpvXbiyDkmPX7ybTT9aDAyzWe8zk2rTrs938W%2B2wM6lzDGSXzUl2grTH8Iv1Hq4LuBKGP6fRJicaHMXNPGnOt0Qc89qApmviFBQzlOK4jrofxnmBTq0XBTs9KKgI1LVPpSqLsCkT8oN%2F17QCSjEDcF%2Bw1HcThMclxuVY9silDTdiDnEyhkGc5xdnpEzsfC5jpzmF%2Fdii%2FPVUJ9X8nXCl8Jj5sZcIHE%2FKNA41IDDng2PokwcylBBXzrAfyWk0p2MY8AeAWbus9AdMpnQG78J7SwnYXMFImTsw6brZvwY6sgGDFBx2kd5IgWc6F5nL4c%2BfWTKAzhy3raaPylDGzsDL7fDOeLwHy2vPJFmTrE3xRE3X55QsrBExOf9NzODTcHxFjrQfgPCK%2B33Ygj0QEl5QhQoqRUoiVm%2B87rT2EgAEdzck57JQvx568DgsARAznWpukKMFljO7SZqFhny3ymrsF4nZOEReBBGlmAp7tKKTfVQEWflBhRKI59k8wL%2By%2BU%2FOmZcjFCeU%2FFtxwHoFUUVF23pn&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20250409T120408Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTYSOHYL5HQ%2F20250409%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=8464783ba4b077caf2bc6511f9dddc141913d5eaa01c86f65b0d7bc35c67d295&hash=f5d453bc000162436713d28a59ed39de9a148ed02230e59c1f817d444e8b6030&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S0097849323002170&tid=spdf-a70da0ad-a69c-4b28-b2c2-8d6be50cb437&sid=6472ce05872ad34ab77a4da572218302f48dgxrqa&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&rh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=120d5956055a0306540257&rr=92d9dd7e0e0f09d4&cc=hk)  |
| 13    | SimTxtSeg: Weakly-Supervised Medical Image Segmentation with Simple Text Cues      |[PDF](https://link.springer.com/content/pdf/10.1007/978-3-031-72111-3_60.pdf?pdf=inline%20link)  |
| 14    | SurgicalPart-SAM: Part-to-Whole Collaborative Prompting for Surgical Instrument Segmentation      |[PDF](https://arxiv.org/pdf/2312.14481)  |
| 15    | Text Promptable Surgical Instrument Segmentation with Vision-Language Models      |[PDF](https://proceedings.neurips.cc/paper_files/paper/2023/file/5af741d487c5f0b08bfe56e11d1883e4-Paper-Conference.pdf)  |
| 16    | Textmatch: Using Text Prompts to Improve Semi-supervised Medical Image Segmentation      |[PDF](https://papers.miccai.org/miccai-2024/paper/0960_paper.pdf)  |
| 17    | TP-DRSeg: Improving Diabetic Retinopathy Lesion Segmentation with Explicit Text-Prompts Assisted SAM      |[PDF](https://arxiv.org/pdf/2406.15764)  |
| 18    | TV-SAM: Increasing Zero-Shot Segmentation Performance on Multimodal Medical Images Using GPT-4 Generated Descriptive Prompts Without Human Annotation      |[PDF](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10778143)  |
| 19    | Universal and extensible language-vision models for organ segmentation and tumor detection from abdominal computed tomography      |[PDF](https://pdf.sciencedirectassets.com/272154/1-s2.0-S1361841524X00055/1-s2.0-S1361841524001518/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEBMaCXVzLWVhc3QtMSJHMEUCIEvDCapOdDypDp5LcPz1TM8fi6BNrNXJAcTmViMEayWNAiEAiDkaQNBvSSxvdpyaQzdkaup%2BpKNtH07pxF8rnrQt7dMqvAUIjP%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAFGgwwNTkwMDM1NDY4NjUiDJgY3yI63mC%2B%2BVlX3iqQBVgyQByoyxEcwG%2B1%2FF0mYxHH9rI3c8cfafC%2FVjeotmmG9Q5U1ZispeyhJztSkg8UGTiRIeuQ%2B%2FGxiSFat2j86T%2B52duhHVQh0axLG95GvozelvG8UW4Ml%2BlZEV69XBC3VLA1UwnlPgayMPVEuiGpgvQdbAdmWblAJRffci3msyme7tUZGdsC61U3GNSNXaENDxI0cMH8tM4NH6g4IaETjX4EmyiMAF3cwwoRXDEV%2BE15XEtDzHGQ2QQvbNLRXbHx45JG3Kcdj5RUox%2FqOUrmOPAdDeyPFkTzAwOFQLj9AfbCnNm%2FQh7c1SB%2FY%2Bljaq8bVmMFjlSBfwYzvOM8jkvPF2cZ5YRX%2BT7dexOSjvmzYvKk%2FlrIPAaLMzPl0BFo8et00p6IcZvAokNdsMWmZ55BQHtDiCtN5wMa6DMiQXg1cJZqMYEO6Pfyij0v%2BmKaE2J2cIv223CNtXROVHHcYNKEtRGkxv97kS6JOKIHvPtFhIi5Xxf6YplzZJUx2SMzDPxUeoUieh8uh9KkKId4N66inVQZKQPotwFTy4EKVsDQH%2BIY9igYTalM0Rlg0RFetL9liU1DwzS2CMIlbMIrf4JQYYbLrd2nxtjpXhR7jsgHAVNa8dqWFNdpuUzMDXGrzuz3ZyhVgvNtFTv231L4%2BvyJmsCWqy0JlZQSTUqseC%2BqmbDl%2FVr%2FrL3YD5kxjv7Pq3v9IeQrcK1eRMOlSrA%2F2EI4hWU21sTHMB4Flh62MGa4IyySj4wOPXzSpXkfK2y6rfpZw7zrQ82aco8L94jsxlwLq0m%2Btc3UbdADiWHm0zpKd7giVATzXa5Pb1LhIw1kb0vxh0Bcno7AcOSz5WekGDnLXqTDtjD9Yu0FG%2B3SIAuHMMQzMOin2b8GOrEB6f08z6YF0GrLlRRMHZM%2BNFgZbufnPj5r3GN566NKZ10IbRLu%2BKvToEhmT9QgthXiwKqeVZl4GYO7v5dU9tS2ZkYp%2FQEkBXyP0MSAfv%2BaquNFtU1b7834pP11xFsq5BPPDV%2FmJCBr%2BvU8QK0RtFNU44Dk1LCGkIDFXTT%2BLTWaZRGJhCpjCFXeCCPzB0CQB6ZGucnG0yBHnJlJDgjtPc9sbKw28nibBHJCi%2BbR3ilr1gJq&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20250409T120656Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTYVFJGWYMO%2F20250409%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=d4d0044574323341b6f74572dd5682eb6b5353c4abaf60793b648ae0e015ac65&hash=bf53dab2efc057a47df99d5a42b2ee610ba7b7e119b7293174dd1eb3b4a4fd2c&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S1361841524001518&tid=spdf-e55dbc46-4bca-4bcb-ad0a-ccd879d98937&sid=6472ce05872ad34ab77a4da572218302f48dgxrqa&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&rh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=120d5956055a02535a5f03&rr=92d9e198df5c09d4&cc=hk)  |
| 20    | VCLIPSeg: Voxel-Wise CLIP-Enhanced Model for Semi-supervised Medical Image Segmentation      |[PDF](https://papers.miccai.org/miccai-2024/paper/1949_paper.pdf)  |
| 21    | Visual-Textual Matching Attention for Lesion Segmentation in Chest Images      |[PDF](https://papers.miccai.org/miccai-2024/paper/2773_paper.pdf)  |
| 22    | VLSM-Adapter: Finetuning Vision-Language Segmentation Efficiently with Lightweight Blocks      |[PDF](https://arxiv.org/pdf/2405.06196)  |










## Anomaly Detection
| Index | Paper Names  | PDF Link       |
|:----:|:----------|:-----------|
| 1    | AdaCLIP: Adapting CLIP with Hybrid Learnable Prompts for Zero-Shot Anomaly Detection      |[PDF](https://arxiv.org/pdf/2407.15795)  |
| 2    | Adapting Visual-Language Models for Generalizable Anomaly Detection in Medical Images     |[PDF](https://openaccess.thecvf.com/content/CVPR2024/papers/Huang_Adapting_Visual-Language_Models_for_Generalizable_Anomaly_Detection_in_Medical_Images_CVPR_2024_paper.pdf)  |
| 3    | CLIP-AD: A Language-Guided Staged Dual-Path Model for Zero-Shot Anomaly Detection      |[PDF](https://arxiv.org/pdf/2311.00453)  |
| 4    | CONTRASTIVE LANGUAGE PROMPTING TO EASE FALSE POSITIVES IN MEDICAL ANOMALY DETECTION      |[PDF](https://arxiv.org/pdf/2411.07546)  |
| 5    | Exploring Zero-Shot Anomaly Detection with CLIP in Medical Imaging: Are We There Yet?      |[PDF](https://arxiv.org/pdf/2411.09310)  |
| 6    | MediCLIP: Adapting CLIP for Few-Shot Medical Image Anomaly Detection      |[PDF](https://arxiv.org/pdf/2405.11315)  |
| 7    | Multimodal Fusion and Knowledge Distillation for Improved Anomaly Detection      |[PDF](https://link.springer.com/content/pdf/10.1007/s00371-024-03723-6.pdf)  |
| 8    | Position-Guided Prompt Learning for Anomaly Detection in Chest X-Rays      |[PDF](https://arxiv.org/pdf/2405.11976)  |
| 9    |Prompting Vision-Language Models for Dental Notation Aware Abnormality Detection      |[PDF](https://www.researchgate.net/profile/Chenlin-Du-3/publication/385145160_Prompting_Vision-Language_Models_for_Dental_Notation_Aware_Abnormality_Detection/links/6791c29195e02f182eb0bb46/Prompting-Vision-Language-Models-for-Dental-Notation-Aware-Abnormality-Detection.pdf)  |
| 10    | Toward Generalist Anomaly Detection via In-context Residual Learning with Few-shot Sample Prompts      |[PDF](https://openaccess.thecvf.com/content/CVPR2024/papers/Zhu_Toward_Generalist_Anomaly_Detection_via_In-context_Residual_Learning_with_Few-shot_CVPR_2024_paper.pdf)  |







## Medical Image Classification
| Index | Paper Names  | PDF Link       |
|:----:|:----------|:-----------|
| 1    | A 360° view for large language models: Early detection of amblyopia in children using multi-view eye movement recordings      |[PDF](https://pmc.ncbi.nlm.nih.gov/articles/PMC11100845/pdf/nihpp-2024.05.03.24306688v2.pdf)  |
| 2    | Adacbm: An adaptive concept bottleneck model for explainable and accurate diagnosis      |[PDF](https://arxiv.org/pdf/2408.02001)  |
| 3    | Aligning human knowledge with visual concepts towards explainable medical image classification      |[PDF](https://arxiv.org/pdf/2406.05596)  |
| 4    | Applications of multimodal generative ai in a real-world retina clinic setting      |[PDF](https://journals.lww.com/retinajournal/fulltext/2024/10000/applications_of_multimodal_generative_artificial.9.aspx)  |
| 5    | Applying object detection and large language model to establish a smart telemedicine diagnosis system with chatbot: A case study of pressure injuries diagnosis system      |[PDF](https://www.liebertpub.com/doi/pdf/10.1089/tmj.2023.0715)  |
| 6    | Assessing the feasibility of chatgpt-4o and claude 3-opus in thyroid nodule classification based on ultrasound images      |[PDF](https://link.springer.com/content/pdf/10.1007/s12020-024-04066-x.pdf)  |
| 7    | Berthop: An effective vision-and-language model for chest x-ray disease diagnosis      |[PDF](https://pmc.ncbi.nlm.nih.gov/articles/PMC10120542/pdf/nihms-1888874.pdf)  |
| 8    |  Bomd: bag of multi-label descriptors for noisy chest x-ray classification  |[PDF](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_BoMD_Bag_of_Multi-label_Descriptors_for_Noisy_Chest_X-ray_Classification_ICCV_2023_paper.pdf)  |
| 9    |  Claude 3 opus and chatgpt with gpt-4 in dermoscopic image analysis for melanoma diagnosis: comparative performance analysis      |[PDF](https://medinform.jmir.org/2024/1/e59273)  |
| 10    | Clip-dr: Textual knowledge-guided diabetic retinopathy grading with ranking aware prompting      |[PDF](https://arxiv.org/pdf/2407.04068)  |
| 11    | Clip-lung: Textual knowledge-guided lung nodule malignancy prediction, in: International Conference on Medical Image Computing and Computer-Assisted Intervention |[PDF](https://arxiv.org/pdf/2304.08013)  |
| 12    | Comparing diagnostic accuracy of radiologists versus gpt-4v and gemini pro vision using image inputs from diagnosis please cases      |[PDF](https://pubs.rsna.org/doi/pdf/10.1148/radiol.240273)  |
| 13    | Comparison of multi-modal large language models with deep learning models for medical image classification      |[PDF](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10687159)  |
| 14    | Comparing the diagnostic performance of gpt-4-based chatgpt, gpt-4v-based chatgpt, and radiologists in challenging neuroradiology cases      |[PDF](https://link.springer.com/content/pdf/10.1007/s00062-024-01426-y.pdf)  |
| 15    | Domain-adapted large language models for classifying nuclear medicine reports      |[PDF](https://pubs.rsna.org/doi/pdf/10.1148/ryai.220281)  |
| 16    | Enhancing chest x-ray datasets with privacy-preserving large language models and multi-type annotations: a data-driven approach for improved classification  |[PDF](https://pdf.sciencedirectassets.com/272154/1-s2.0-S1361841524X00079/1-s2.0-S1361841524003086/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEBUaCXVzLWVhc3QtMSJHMEUCIFlybi85ikujXjBMZefNM2XtUbYNd3DyUkWzCf9fWkveAiEA%2BmURGeNpDjIo%2BCxtgnrp2z5A7xAgBCl5EbloeSsHzJ8quwUIjv%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAFGgwwNTkwMDM1NDY4NjUiDHCEfDnawnrlU11ZKSqPBR82pdLURcxnzQ0f28DqWk5xeXIs7zyz5be1wrpA1N1CossKD01zd%2FYnTIUfnZC%2Fv%2F%2FS%2BHgCNu%2F4meojz2CnbqD8pgPeVbOHma4608oJY3fk5uQuNkMdUVMPX0V0yKa0nbqbcKFpa38Fouq5DAs%2BhrdXqTyK7BKaY4TlQtsrDuCsP4uBj3DaMkUC3go45oPhmEU1toZyeTDKuSCQhXsB4rpPvFUIDVi0P2%2BkjaeHW7TN50XR%2Bbs%2B7HV0hq2Y%2FvmsybG6300Y56NMNlyq13x%2FUNsomPnvs%2FoDwXMXGexaHZJI6weCgGwtZUlHAI8tl6Azez7u7Zlnz3RfUy%2BSVIr29mydZdotzcW06gSCjfoCEFQsbuWSZDBHdwozI8Hy1sl5ZOo%2Fse8aAF%2BFzfjo3zsziSGeI4YluzCkZlsw2byjv1vTPNbW5Ogin796ntlHRJOhWnxwThfTdD7AwRPC4bs%2ByzhRycIvyPzvyjMWMU6UEehsLBTaTr%2F3YMmhZvN8ZShNTiT9RT0VE42n8ROF4%2BizQ%2B4Ne1Whu%2BuvgWU4mxSHqEIRN7TPY7AH9Y1uqbObiY4GVT7LSC32gU3dgH7bdMvcNQqA%2FjC9zz%2BZWnRaNs4ztbAF20G%2FHB6YMxfzH9dKmR6yA65Bq2wJaaaFcuanpNeqVgCIRYwxIyMGZxie4OrDoRR8mrlzW0hlSImnPR2QOeULkJfGXM1Gj1kYAltLkYlPcQomx0OJgOjWIjil4Jw%2FajuLXC9v6HkOEliUN52OXsrCJz1WLHy2oY0dE7HmdREeZIOyb4V3Oee%2BO3i4uwY37292jTwzSAzxruSQKKE570AY4NGFQcIuAMJLuYTcLwX5LKkD6NmE7GdaJRAw13UIlvcw%2FNnZvwY6sQEQFivi%2FliY%2FiLapttrzLn75jdlAD1fstokw4PofC1wpsAYGlbAq1OSwRnk7onloF%2Fv%2B%2F3lllsmcJVbV6K98F0OESbrqyrNgfue1fFIDPvXBB8bvQ8HrVFt0sFxMDTukRs1MxCPfK5Gj6ZFSk0wmGB3uYr5%2BTHDCRkJ%2BdVwJhW1BupPwaTOPPqxdhpBJDymHF36kezlmO2%2FQ5QMTgj%2FwqYFViBIrH6lWNjFeYYysliszRw%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20250409T131241Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTYUNPM3AXC%2F20250409%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=8c83ed32dd5c3752b556ed68ddd0867034ae92590c842209281501e0989c187d&hash=75289fbda9ceac932837a5d1d37b7d184335fcd7309e18fe0eee169b4470163a&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S1361841524003086&tid=spdf-d49e668b-7f9d-4e39-bd0f-6939f42118b4&sid=6472ce05872ad34ab77a4da572218302f48dgxrqa&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&rh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=120d595605025353065651&rr=92da41e16bc77be7&cc=hk&kca=eyJrZXkiOiJFZlRyTHJFS01mSUp6QWVGQUVZWURrR041c0gyKzZtS2NsWkFKbUh4Mlo2dDJac3lyVzBFT3k5MVBIUEwxVGYxd0FxVTZMTUpuZmxKcldhVytBdlBQQ3c1ZzlMUTdJbzJqdkx3amhGdXlqWnRSUXQ4RlBCTnNIUnVzVWQrcUJrY2xPQm5lVjVMZHc3dUVrWUJmYzBubkJJOFJwbVp3YXBKV0xrWkFxcmlvVy9rNHg4YSIsIml2IjoiZjNjNzdjMmQ2NWQ2ODFiZWNjNzY0Y2YxM2ViMzI5ZTgifQ==_1744204365656)  |
| 17    | Enhancing gait video analysis in neurodegenerative diseases by knowledge augmentation in vision language model      |[PDF](https://arxiv.org/pdf/2403.13756)  |
| 18    |  Hia: Towards chinese multimodal llms for comparative high-resolution joint diagnosis      |[PDF](https://papers.miccai.org/miccai-2024/paper/1207_paper.pdf)  |
| 19    | In-context learning enables multimodal large language models to classify cancer pathology images      |[PDF](https://www.nature.com/articles/s41467-024-51465-9.pdf)  |
| 20    | Insight: A multi-modal diagnostic pipeline using llms for ocular surface disease diagnosis   |[PDF](https://arxiv.org/pdf/2410.00292)  |
| 21    | Language-enhanced local-global aggregation network for multi-organ trauma detection     |[PDF](https://papers.miccai.org/miccai-2024/paper/1056_paper.pdf)  |
| 22    | Mpoxvlm: A vision-language model for diagnosing skin lesions from mpox virus infection      |[PDF](https://arxiv.org/pdf/2411.10888)  |
| 23    | Multimodal breast cancer diagnosis based on multi-level fusion network      |[PDF](https://link.springer.com/chapter/10.1007/978-981-19-7943-9_19)  |
| 24    | Performance evaluation of multimodal large language models (llava and gpt-4-based chatgpt) in medical image classification tasks      |[PDF](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10628740)  |
| 25    | Pneumollm: Harnessing the power of large language model for pneumoconiosis diagnosis      |[PDF](https://pdf.sciencedirectassets.com/272154/1-s2.0-S1361841524X00055/1-s2.0-S1361841524001737/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEBQaCXVzLWVhc3QtMSJHMEUCIQDO7NmV4ZUETWYRRWj5eHW8GRnV%2BWQbFmfcj0uMV9EOLwIgTWzXIPWgizNHAB470dtcHizSpstCOQ80GKC1Klyd5e8qvAUIjf%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAFGgwwNTkwMDM1NDY4NjUiDJA4cHdSC036sFDftiqQBfJkecLrXULHU%2FRoXI51GpfmPv8QBYIyxMV1pHIKTv7mYYskd%2BojZyLpitrCHMGSt99cooPdfS8uR2n7VK4rSwJaAIjULqcTgl%2Ft50oFSIT5%2FBibbKV%2BAF419vaOerI3ZBgdYQVXgm%2BiIA1MMWwvdp30ko1tOATjQY87th%2BzZjAGDgAysyF7nZupUHMsR3UWzVOlrtVywe33v4aQhtAY7oy9Cf%2FlEe0et9qazL%2Ff68v5npfNxYklIVKpHtKw4W%2Fa46bVKqKo8nfUM475USfltmktpz2BeIAY5hef6HPOTOKIDU1zV49JmMfafW6Vl1tEJ0tXGrfgpR8SH7MQKABXUVQX4bDnahnUACbHRcLfe0X20u4YVuzZcvihMMJn2XWziY6bebgpyzUMlV6kkxQdRSznZNDv%2BtoDOQPMGmHI00MsCtegJoocwu5DhVjElvAValkFErqsrcVPdP3CAvEQuCDW677pessg5XbuHMXBfapnlorQM96bFqp%2BjoyiOkJGKzgRB30%2BBkl4dxGJr2DyaF%2BKqp%2FkFZhFNpo%2BqSUd6itEmym8GGa90IkwyaoEV7pZncMvWSBVGzS4Lx7BatPix07rmOD5a3B%2FhngqmNR%2FrditX9%2BAD2fWh1ImR3Es7xkiQJ57Qy1gOGaaWEEz65HRsQ8ujdiT0whXPj6XdUE5G%2BanisruZpoGVWq2Yj4qLiTa3eSOVLKZwVszoKOIcKcJzHtaZQWxxliZAEU%2Fiv%2FfCdb5EfVgqEWtgcg1kP4Fs7c%2BtTAwKqfuzTS4JGNsihnHbrPXE7hTAAIjPfDqSqXyeHuXkBEUvxUV3xkIbEnVrwsqpR8DWWZpZBkngQdkZW66gI9lO9m80I%2FvsNA641NoPmedMPTC2b8GOrEB2650WLLv%2Fyg%2FY8HWYx9gifwT9RzSTAerwxz1yjIMjBQ2tHkXiIm1CRdNQ9EwmSX4l8lNxyZftmyQzKbW%2FLb5EP%2BI6RN2HBUDN7%2BhHTI%2FAMYaqPiv15oWmG%2FeWj0VqJYx2OCrC2fKywxEN1eY0Pl%2BMG2w742pUe%2BZkBHtpF0vJsUPVO%2FtZ6DTdftqk%2BlFJiQN5kUmsZLpe0L6B9b2QQf7lv6dvxbk3Bny%2BpJBe2ZjI5Fl&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20250409T131450Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTYSJZVUUOH%2F20250409%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=c2e88531e13264e2535df80d8c3498e2a8b7c93c3846d7f7ffb507cdb0022916&hash=a42663dea8ae8689a265176bf852dd81972ffee2a367758e1d4bbd09e23e4111&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S1361841524001737&tid=spdf-2da3a5bd-ea1c-49af-8c15-0c61e7073f2e&sid=6472ce05872ad34ab77a4da572218302f48dgxrqa&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&rh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=120d595605025357525603&rr=92da4511d8c27be7&cc=hk)  |
| 26    | Remoni: An autonomous system integrating wearables and multimodal large language models for enhanced remote health monitoring      |[PDF](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10596778)  |
| 27    | Stealing knowledge from pre-trained language models for federated classifier debiasing      |[PDF](https://papers.miccai.org/miccai-2024/paper/3064_paper.pdf)  |
| 28    | Text-guided foundation model adaptation for pathological image classification      |[PDF](https://arxiv.org/pdf/2307.14901)  |
| 29    |  Transforming medical imaging: A vqa model for microscopic blood cell classification     |[PDF](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10750791)  |
| 30    | Xplainer: From x-ray observations to explainable zero-shot diagnosis      |[PDF](https://arxiv.org/pdf/2303.13391)  |




## Medical Image Synthesis
| Index | Paper Names  | PDF Link       |
|:----:|:----------|:-----------|
| 1    | A vision–language foundation model for the generation of realistic chest X-ray images      |[PDF](https://www.nature.com/articles/s41551-024-01246-y)  |
| 2    | Enhancing Chest X-ray Diagnosis with Text-to-Image Generation: A Data Augmentation Case Study      |[PDF](https://pdf.sciencedirectassets.com/271537/1-s2.0-S0141938224X00025/1-s2.0-S0141938224000994/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEBYaCXVzLWVhc3QtMSJHMEUCIQDZFwZq8AKhv8fMjucZwEGlEmxFMGeTXEmNrl37VChTmAIgUr1XQN72iXzFIBxbj89f%2BZLmloYt1JBVBaSFOjOd8gQqvAUIjv%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAFGgwwNTkwMDM1NDY4NjUiDAxcHHVeTAblXvtL1yqQBVp%2BzbMgx4kOwn8LKBv%2Bvc5ylrIQgqXDrfB1RDvXMUIkVgo681T5ALmBM2G1hw7UEXY4G75js4sKZO1mIjZDL%2B9PQ8asRsixOTr%2Fh0Ah07BuPVYMgLmyuPQMW3R1e%2BLsE6bVtsPra6f4iH6zww2jBtrqwVplCQfJMMDvsEmoiA6ATVtpGR9CFIqDwg59hBFH01V47qoFuU75yqhAmDxVvDiGMW01qbCIhtAAoNOzT8ZyaALibbx%2FUGrDJCBhmwpGvUVvkfBp8PkAqVIPwEzMUlHRN4ialsg8%2BzN2kL3ieRFlfqLqNZgM%2BWtHzRw%2FjahRla6%2BqwQJtieVr5N8zhHOODZYzRJ54ELNbayL57cppYvOqAsRF%2FlGICoenR9LJMB81%2F1Zi8Q4oLMUkA760CPKyupFuXEXpZ1VRhDHZ73l7uR2MQvoCI5rNgImPo0Ngj%2B%2BpZ4dy3jK6s3549dhCdZuNAHLrcdpgs%2FwoBStjBiLF0RpVbpNAyus9bzbiJYymcmUeuyMFMJOa6R10t7IX1IZhZtvAaOAlp4ICN6gJlr%2FoCazv2OL1V2oUGgsEkeuyThAa%2Fe%2F8U7JvEBS%2BPxj2cg4BejpbYtgSY%2BivlfNaVgBGmW3X3FCs7ECwW%2B10F5XbnVcUYbOluVcNP%2BJ8RRGShPObnNLeaRkCI6Q0hVxYnzbvnZmqoHxn2bNfqr7CnQrjp4rwvoNp4pO6xHgEWTf9NiW1lHdr4nfkyZPV9%2FnMqjoytewzZA656FiiG%2BgGywKvPgPUN2cXVtwbl%2B3ytHg%2F93frwZ%2BCYQKK7oFEwkmHVsdPiwlZmb7kpJdusJUgQqGt5QWBocQ8WPcoym41Qq8He7zlG2ZNzocFweeFl%2Fyvv%2FbG8%2FWMJ7h2b8GOrEB%2FaPro0M3NjVL4FkiwF4%2B3z7fhnUKWzpNiWbmv5xDsxs68ATEpFf5jg%2FrCY19tM8FFOgJJFWmF2YA8%2Fg8xukRPzBvThjm7%2BWYbAhv1BmvWonKIgGeAUz05KqGS6zwJFMoRW1ywiGz4vnS3vwaMTOVwq5YmtBP9g9yb37nD2qLxNVYxeDxsK91M%2FN7pycmfLuvHNTIydwiAS%2BFDwoP0JxL72JXNhaJtYmZ%2BiaPcsQZv%2B0n&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20250409T132220Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTYRR3YI26Z%2F20250409%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=11799cef2c5ad4bbc278fdeff3bd4f69c32af3b429171466bedafba3b885e60d&hash=a5e5155b007eebd18d35782e08fb12fd54ec44cfd1799e7ce2358712e5966cda&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S0141938224000994&tid=spdf-8f83767c-d704-4b86-8884-9ea1fade06ec&sid=6472ce05872ad34ab77a4da572218302f48dgxrqa&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&rh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=120d595605025252530305&rr=92da500dbcb2dd48&cc=hk)  |
| 3    | Finetuning of GLIDE Stable Diffusion Model for AI-Based Text-Conditional Image Synthesis of Dermoscopic Images      |[PDF](https://www.frontiersin.org/journals/medicine/articles/10.3389/fmed.2023.1231436/pdf)  |
| 4    | GenerateCT: Text-Conditional Generation of 3D Chest CT Volumes      |[PDF](https://arxiv.org/pdf/2305.16037)  |
| 5    | HistoSyn: Histomorphology-Focused Pathology Image Synthesis      |[PDF](https://papers.miccai.org/miccai-2024/paper/0215_paper.pdf)  |
| 6    | Medical Image Synthesis via Fine-Grained Image-Text Alignment and Anatomy-Pathology Prompting     |[PDF](https://arxiv.org/pdf/2403.06835)  |
| 7    | MedSyn: Text-Guided Anatomy-Aware Synthesis of High-Fidelity 3-D CT Images      |[PDF](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10566053)  |
| 8    | Vision-Language Generative Model for View-Specific Chest X-ray Generation      |[PDF](https://arxiv.org/pdf/2302.12172)  |






## Medical Image-Text Retrieval
| Index | Paper Names  | PDF Link       |
|:----:|:----------|:-----------|
| 1    | 3D-MIR: A BENCHMARK & EMPIRICAL STUDY ON 3D MEDICAL IMAGE RETRIEVAL IN RADIOLOGY      |[PDF](https://arxiv.org/pdf/2311.13752)  |
| 2    | BIMCV-R: A Landmark Dataset for 3D CT Text-Image Retrieval     |[PDF](https://arxiv.org/pdf/2403.15992)  |
| 3    | Medical Cross-Modal Prompt Hashing with Robust Noisy Correspondence Learning      |[PDF](https://papers.miccai.org/miccai-2024/paper/2150_paper.pdf)  |
| 4    | Vision and Structured-Language Pretraining for Cross-Modal Food Retrieval      |[PDF](https://pdf.sciencedirectassets.com/271018/1-s2.0-S1077314224X00089/1-s2.0-S1077314224001528/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEBUaCXVzLWVhc3QtMSJGMEQCIC3VMDB0kACTSsbagk3tnJf%2FKVU8oc2Vp853JPdGuwvGAiB24P0oOBuQcZAw659zJeNUnLIsA8QXHYtdFkjGphIR%2Fiq7BQiO%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAUaDDA1OTAwMzU0Njg2NSIMpJAGc3kIW0yH0CuIKo8FVn2Rwi%2FD0%2BgvkCbE0Kr6Bb8na007EuIAFwhguS0MNidaEJkDuwHLVPsyYS1oHAg0cazDNqgrm%2ByfjqiyDv6Y3bySVfHUHqjkrVSfclLrY1VqML1Oe0AtRNcUl8cu5vRd%2Bwa6LLevhHOPsop9%2Fnnrvwzk5IcEhH9oRb0cH2nKnUGNgQwd8c%2BM%2FyI6auP9HT9OLwGD6wEPe025VO0%2Bzt%2FVemcrWh9JZoT2Ik10IWS6Fk742DtdUwZeEXJ6d02XRpVOc6H8G2orW1B2cOH78Cuu4tT4s8GqPbdu6W42XNvKaQya3tE9GLOOKSC94xmNDPv7ioozt1UQCsVxU2aGT00dmGimtosjz%2B3F5V3%2B%2BfTnl%2FaCc6jkcIJ3DCbQ7mkpz7qxCCQt%2BcDWRQ3O0ioSQ050IMamWPMUbvHEgkuLszGHhkOhhTh1kO1V8IFPwwzYuH7CqqTM70BCu7GL29oTMFo5%2FJno12VZqdnGzNDrwVN6R5UQJiZmBgxdVaW%2BfXREf0i%2Bl%2FdK9nQzGel6XFSBHrrEu7qNyCVxn5JAbbF%2FEFwpLdiHfqOOANXC2xSyZ3iKVUeechH4iQ05eUyeyXL7gALQYEdAsIKAeD%2FG21uooff4V%2BkopR0TVfGSgSVpf0jeruJJyvxsDegeByaLmU%2B6Rbhvc3gnPXLgRNGgR1D%2Bc%2B8rdqak6kqlKOe17qRbuzCPF42YsOzSFRJTJrPcTzs0ScYl09Beozb9aimo2BIodF%2F7Xppp2bsEW9IHwDYo90CmJVvxsH%2BS9fnXh2U4Qis1o1G5AikuNXe5VBsy4Rf55kUvDmzEriW%2FE7yG08C%2BHVp2b0we26yrMmiYDt8vVlo891DTuCBToRmF4QCiq8CW%2BB3X9TDG4Nm%2FBjqyAUq0%2BkYE1FGQ9pyuj1q62F2S%2FAOgdUuZmlkBfdy42Tdd8oAiL9EPvFV78lJzETCjrD7qM7YKHusEvsVsDU5WNTn7%2FYO8TGRyR2WTXLXrcJb%2F1MOgHFqUr3YzUdJUjiyWfDWftQSylM%2FHl9SCqstCcLwQ%2FeK2b6HpDMgkkrVK2F7jHFo8TT2Rp0LDp1o4lMUuJrbTwkRQhb%2B3U6Y0LqjvZZt7ViC4G%2FfVoj2ZBx9TKUSWliM%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20250409T133622Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTY5EEAGTGT%2F20250409%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=703db15078b74abe84a6a6d67fa339c19483230e7dd9a32f08db09dba5e72b80&hash=22127641c0726200583c8cd87a86b2cb02ca3dcb0212246cff0dd6d7ffafd8fc&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S1077314224001528&tid=spdf-60b81dcd-a290-4c3d-b774-e51b7a9ea08a&sid=6472ce05872ad34ab77a4da572218302f48dgxrqa&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&rh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=120d5956050251565a0551&rr=92da649b6d5ddf9d&cc=hk)  |
| 5    | Vision-Language Modelling for Radiological Imaging and Reports in the Low Data Regime      |[PDF](https://arxiv.org/pdf/2303.17644)  |
| 6    | X-TRA: Improving Chest X-ray Tasks with Cross-Modal Retrieval Augmentation      |[PDF](https://arxiv.org/pdf/2302.11352)  |


## Medical Multi-task Learning
| Index | Paper Names  | PDF Link       |
|:----:|:----------|:-----------|
| 1    | A Novel Detection and Classification Framework for Diagnosing Cerebral Microbleeds Using Transformer and Language      |[PDF](https://pmc.ncbi.nlm.nih.gov/articles/PMC11504022/pdf/bioengineering-11-00993.pdf)  |
| 2    | Boosting Medical Image-based Cancer Detection via Text-guided Supervision from Reports      |[PDF](https://arxiv.org/pdf/2405.14230)  |
| 3    | Cap2Seg: Leveraging Caption Generation for Enhanced Segmentation of COVID-19 Medical Images     |[PDF](https://www.frontiersin.org/journals/physics/articles/10.3389/fphy.2024.1439122/pdf)  |
| 4    | CAT-ViL: Co-attention Gated Vision-Language Embedding for Visual Question Localized-Answering in Robotic Surgery      |[PDF](https://arxiv.org/pdf/2307.05182)  |
| 5    | ChEX: Interactive Localization and Region Description in Chest X-Rays      |[PDF](https://arxiv.org/pdf/2404.15770)  |
| 6    | fTSPL: Enhancing Brain Analysis with FMRI-Text Synergistic Prompt Learning      |[PDF](https://papers.miccai.org/miccai-2024/paper/2709_paper.pdf)  |
| 7    | MAIRA-2: Grounded Radiology Report Generation      |[PDF](https://arxiv.org/pdf/2406.04449)  |
| 8    | miniGPT-Med: Large Language Model as a General Interface for Radiology Diagnosis      |[PDF](https://arxiv.org/pdf/2407.04106?)  |
| 9    | SAT-Morph: Unsupervised Deformable Medical Image Registration Using Vision Foundation Models with Anatomically Aware Text Prompt      |[PDF](https://link.springer.com/content/pdf/10.1007/978-3-031-73471-7_8.pdf?pdf=inline%20link)  |
| 10    | Surgical-VQLA++: Adversarial contrastive learning for calibrated robust visual question-localized answering in robotic surgery      |[PDF](https://pdf.sciencedirectassets.com/272144/1-s2.0-S1566253524X00093/1-s2.0-S1566253524003804/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEBUaCXVzLWVhc3QtMSJHMEUCIFlybi85ikujXjBMZefNM2XtUbYNd3DyUkWzCf9fWkveAiEA%2BmURGeNpDjIo%2BCxtgnrp2z5A7xAgBCl5EbloeSsHzJ8quwUIjv%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAFGgwwNTkwMDM1NDY4NjUiDHCEfDnawnrlU11ZKSqPBR82pdLURcxnzQ0f28DqWk5xeXIs7zyz5be1wrpA1N1CossKD01zd%2FYnTIUfnZC%2Fv%2F%2FS%2BHgCNu%2F4meojz2CnbqD8pgPeVbOHma4608oJY3fk5uQuNkMdUVMPX0V0yKa0nbqbcKFpa38Fouq5DAs%2BhrdXqTyK7BKaY4TlQtsrDuCsP4uBj3DaMkUC3go45oPhmEU1toZyeTDKuSCQhXsB4rpPvFUIDVi0P2%2BkjaeHW7TN50XR%2Bbs%2B7HV0hq2Y%2FvmsybG6300Y56NMNlyq13x%2FUNsomPnvs%2FoDwXMXGexaHZJI6weCgGwtZUlHAI8tl6Azez7u7Zlnz3RfUy%2BSVIr29mydZdotzcW06gSCjfoCEFQsbuWSZDBHdwozI8Hy1sl5ZOo%2Fse8aAF%2BFzfjo3zsziSGeI4YluzCkZlsw2byjv1vTPNbW5Ogin796ntlHRJOhWnxwThfTdD7AwRPC4bs%2ByzhRycIvyPzvyjMWMU6UEehsLBTaTr%2F3YMmhZvN8ZShNTiT9RT0VE42n8ROF4%2BizQ%2B4Ne1Whu%2BuvgWU4mxSHqEIRN7TPY7AH9Y1uqbObiY4GVT7LSC32gU3dgH7bdMvcNQqA%2FjC9zz%2BZWnRaNs4ztbAF20G%2FHB6YMxfzH9dKmR6yA65Bq2wJaaaFcuanpNeqVgCIRYwxIyMGZxie4OrDoRR8mrlzW0hlSImnPR2QOeULkJfGXM1Gj1kYAltLkYlPcQomx0OJgOjWIjil4Jw%2FajuLXC9v6HkOEliUN52OXsrCJz1WLHy2oY0dE7HmdREeZIOyb4V3Oee%2BO3i4uwY37292jTwzSAzxruSQKKE570AY4NGFQcIuAMJLuYTcLwX5LKkD6NmE7GdaJRAw13UIlvcw%2FNnZvwY6sQEQFivi%2FliY%2FiLapttrzLn75jdlAD1fstokw4PofC1wpsAYGlbAq1OSwRnk7onloF%2Fv%2B%2F3lllsmcJVbV6K98F0OESbrqyrNgfue1fFIDPvXBB8bvQ8HrVFt0sFxMDTukRs1MxCPfK5Gj6ZFSk0wmGB3uYr5%2BTHDCRkJ%2BdVwJhW1BupPwaTOPPqxdhpBJDymHF36kezlmO2%2FQ5QMTgj%2FwqYFViBIrH6lWNjFeYYysliszRw%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20250409T134228Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTYUNPM3AXC%2F20250409%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=181e671fdd353e5a2832ad08ad450d5c25b3108f3478adf92dd91419d5252a2f&hash=6f77bc086f61e85bc434bdfc047adf7d4f48a64d83e6a071c773f55dead5213c&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S1566253524003804&tid=spdf-76f7dcca-59ff-4fe5-bf66-a937bbef34df&sid=6472ce05872ad34ab77a4da572218302f48dgxrqa&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&rh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=120d5956050251065b0354&rr=92da6d8d3b67df9d&cc=hk)  |
| 11    | Towards Interactive and Interpretable Image Retrieval-Based Diagnosis: Enhancing Brain Tumor Classification with LLM Explanations and Latent Structure Preservation      |[PDF](https://link.springer.com/content/pdf/10.1007/978-3-031-66535-6_35.pdf?pdf=inline%20link)  |
| 12    | VILA-M3: Enhancing Vision-Language Models with Medical Expert Knowledge      |[PDF](https://arxiv.org/pdf/2411.12915)  |




## Other Image Analysis Tasks
| Index | Paper Names  | Tasks  | PDF Link       |
|:----:|:----------|:----------|:-----------|
| 1    | M2Trans: Multi-Modal Regularized Coarse-to-Fine Transformer for Ultrasound Image Super-Resolution     |Medical Image Super-resolution |[PDF](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10663841)  |
| 2    | Spatially Covariant Image Registration with Text Prompts     |Medical Image Registration |[PDF](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10684804)  |
| 3    | Efficient Medical Images Text Detection with Vision-Language Pre-training Approach    |Object Detection |[PDF](https://proceedings.mlr.press/v222/li24e/li24e.pdf)  |
| 4    | Multiple Prompt Fusion for Zero-Shot Lesion Detection Using Vision-Language Models     |Object Detection |[PDF](https://link.springer.com/content/pdf/10.1007/978-3-031-43904-9_28.pdf?pdf=inline%20link)  |
| 5    | Zero-Shot Nuclei Detection via Visual-Language Pre-trained Models     |Object Detection |[PDF](https://arxiv.org/pdf/2306.17659)  |































