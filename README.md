![image](https://github.com/user-attachments/assets/68f72c53-399f-4495-9275-6865656cf12f)#Taming Vision-Language Models for Medical Image Analysis: A Comprehensive Review
---

##The summary of natural and medical VLMs which are utilzed in medical image analysis tasks.
---
| Index | Model Names  | Paper Names  | Natrual\Medical    | Paper Link       |
|:----:|:----------|:----------|:-------------------------|:-----------|
| 1    | VL-BERT| VL-BERT: Pre-training of Generic Visual-Linguistic Representations      | Natrual       |[PDF](https://arxiv.org/pdf/1908.08530)  |
| 2    |CLIP| Learning Transferable Visual Models From Natural Language Supervision      | Natrual       |[PDF](https://proceedings.mlr.press/v139/radford21a/radford21a.pdf)  |
| 3    | GLIDE| GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models      | Natrual       |[PDF](https://arxiv.org/pdf/2112.10741)  |
| 4    | BLIP| BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation      | Natrual       |[PDF](https://proceedings.mlr.press/v162/li22n/li22n.pdf)  |
| 5    | GLIP| Grounded Language-Image Pre-training      | Natrual       |[PDF](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Grounded_Language-Image_Pre-Training_CVPR_2022_paper.pdf)  |
| 6    | Stable Diffusion| High-resolution image synthesis with latent diffusion models      | Natrual       |[PDF](https://openaccess.thecvf.com/content/CVPR2022/papers/Rombach_High-Resolution_Image_Synthesis_With_Latent_Diffusion_Models_CVPR_2022_paper.pdf)  |
| 7    | ALBEF| Align before Fuse: Vision and Language Representation Learning with Momentum Distillation      | Natrual       |[PDF](https://proceedings.neurips.cc/paper_files/paper/2021/file/505259756244493872b7709a8a01b536-Paper.pdf)  |
| 8    |BLIP-2| BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models      | Natrual       |[PDF](https://proceedings.mlr.press/v202/li23q/li23q.pdf)  |
| 9    | Caption Anything| Caption anything: Interactive image description with diverse multimodal controls      | Natrual       |[PDF](https://arxiv.org/pdf/2305.02677)  |
| 10    | DALL·E 3| Improving Image Generation with Better Captions      | Natrual       |[PDF](https://cdn.openai.com/papers/dall-e-3.pdf)  |
| 11    | Dreamlike Photoreal| -      | Natrual       |- |
| 12    | EVA-CLIP| EVA-CLIP: Improved Training Techniques for CLIP at Scale      | Natrual       |[PDF](https://arxiv.org/pdf/2303.15389)  |
| 13    | Gemini 1.0| Gemini: A Family of Highly Capable Multimodal Models      | Natrual       |[PDF](https://arxiv.org/pdf/2312.11805)  |
| 14    | Grounding DINO| Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detection      | Natrual       |[PDF](https://arxiv.org/pdf/2303.05499) |
| 15    |MiniGPT-4| MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models      | Natrual       |[PDF](https://arxiv.org/pdf/2304.10592)  |
| 16    | MiniGPT-v2| MiniGPT-v2: large language model as a unified interface for vision-language multi-task learning      | Natrual       |[PDF](https://arxiv.org/pdf/2310.09478)  |
| 17    | SAM| Segment Anything      | Natrual       |[PDF](https://openaccess.thecvf.com/content/ICCV2023/papers/Kirillov_Segment_Anything_ICCV_2023_paper.pdf)  |
| 18    | SAT| One Model to Rule them All: Towards Universal Segmentation for Medical Images with Text Prompts      | Natrual       |[PDF](https://arxiv.org/pdf/2312.17183)  |
| 19    | Vita-CLIP| Vita-CLIP: Video and text adaptive CLIP via Multimodal Prompting      | Natrual       |[PDF](https://openaccess.thecvf.com/content/CVPR2023/papers/Wasim_Vita-CLIP_Video_and_Text_Adaptive_CLIP_via_Multimodal_Prompting_CVPR_2023_paper.pdf)  |
| 20    | Chexagent| A Vision-Language Foundation Model to Enhance Efficiency of Chest X-ray Interpretation      | Natrual       |[PDF](https://arxiv.org/pdf/2401.12208)  |
| 21    | Claude 3 Opus| -      | Natrual       |-  |
| 22    | Gemini 1.5 Pro| Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context      | Natrual       |[PDF](https://arxiv.org/pdf/2403.05530)  |
| 23    | GPT 4V| -      | Natrual       |-  |
| 24    | GPT 4 Turbo| Gpt-4 technical report      | Natrual       |[PDF](https://arxiv.org/pdf/2303.08774)  |
| 25    | GPT 4o| Gpt-4o system card      | Natrual       |[PDF](https://arxiv.org/pdf/2410.21276?)  |
| 26    | LLaMA 3| The Llama 3 Herd of Models      | Natrual       |[PDF](https://arxiv.org/pdf/2407.21783)  |
| 27    | Clinical-BERT| Clinical-BERT: Vision-Language Pre-training for Radiograph Diagnosis and Reports Generation      | Medical       |[PDF](https://ojs.aaai.org/index.php/AAAI/article/view/20204/19963)  |
| 28    | MedCLIP| MedCLIP: Contrastive Learning from Unpaired Medical Images and Text      | Medical       |[PDF](https://pmc.ncbi.nlm.nih.gov/articles/PMC11323634/pdf/nihms-2012083.pdf)  |
| 29    | BiomedCLIP|BiomedCLIP: a multimodal biomedical foundation model pretrained from fifteen million scientific image-text pairs      | Medical       |[PDF](https://arxiv.org/pdf/2303.00915)  |
| 30    | BioViL| Learning to Exploit Temporal Structure for Biomedical Vision-Language Processing      | Medical       |[PDF](https://openaccess.thecvf.com/content/CVPR2023/papers/Bannur_Learning_To_Exploit_Temporal_Structure_for_Biomedical_Vision-Language_Processing_CVPR_2023_paper.pdf)  |
| 31    | CXR-CLIP| CXR-CLIP: Toward Large Scale Chest X-ray Language-Image Pre-training      | Medical       |[PDF](https://arxiv.org/pdf/2310.13292)  |
| 32    |FLAIR| A Foundation Language-Image Model of the Retina (FLAIR): Encoding Expert Knowledge in Text Supervision      | Medical       |[PDF](https://pdf.sciencedirectassets.com/272154/1-s2.0-S1361841524X00079/1-s2.0-S1361841524002822/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEBAaCXVzLWVhc3QtMSJGMEQCIBRfR5e7VIKC0di1aaYtnC6tvGpg4BdAyIbQ6S1mNkrwAiApdlqoiQOxLhiiYz0%2BqBKfqNXHOOn%2FLeXB4mG1rym%2Bwiq8BQiJ%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAUaDDA1OTAwMzU0Njg2NSIMsUsxUEIQ2fksccqHKpAF1aIZ9rXktwjjarP7yRmPmlbHC7HVG4m8sET91UbVt7WQMbo5VhXiXedSi5uJpseFnqBHq1KLoiSRTPtyoucukTYLKUnR82CZOiu%2B7sQQBZeTG%2BnTHT538lcPw6QtJ2Cfpx%2BVuP7EydGp660pfJd7hUY5C7SnFKgXNGVrf4f4D89hAunxGOb3GjZYZL1X5jx3wFwj0Fa9nOYuY2hA%2FfoqXnKTxpdOvoOs6Ya7wETBKo1Ft65Km3pBTS30GX1uNJK3FtYB1V3QM3i7Us5DazqoZHnS57LCjCBmPf9tOX%2F7hWyExw7oxi6wQCwU4%2FIncXNkNFWqvPF7%2BVBKyWgRW2LPEuWHnFz4HrePDo5PJ7tPH2VjyVm%2F99zSFANVET7YW4%2BK%2FbHzTCYEvko1aO5hjUx4LahQ91nA%2FRB6TaridfwlsQoYfc5lT%2FiUSi8m1eiKt%2B5IzHUZMEFWVFkxONnTT3mDCWUVEo%2F19S27h8QElWIXm5XTpUJpRoQZ6craRiBf0ZDnVR0bOazt7RgzZvs8gUUatBHjszn2DrGNDMEDzi%2BxBTm3bBbZ59SSHifGLgXi8TJMgevthC9MQNkOJiV6HYaU9onJvkCpzVUXB5ggEMx8dchthcRquUFbwinNm03epRY1QGFx%2FaH5xeHW%2F%2B1ZO799bxKXMz2Qhpzn%2BDRwybTH2yDTBrsMoUHPaxyGWlQKoW2I1NFXu1hAyP7EPZMynYjHauIa0AT%2FypQOZ9S5rbW0OTGLP6dosgCKIJzllJhf2YWXaDEd1qjeiESEAfMKjpF44%2B6cEHqnfIPiNWOBd1EGcBoFr5q7ajtJ0ByQ9BDNnz7XkqSAm1Upv0tPA7YhkwX1bc0H%2FL5eUHsdwe7TLDISF%2F4w9MjYvwY6sgEplNYS2JaV1RCdjqMGQ8WreDFXscPj41%2FlwrY4IYyaLm16A%2BsNjJU0oSutzsChtrixn5BiynY%2B3QVGtMLM1r3cLnMZgUVzMsxTI58IU6WqP1N%2BnGAQ%2FrDyalL%2FCIVphZ7YAEW9ld2RT922aoOHgz%2BQlY5OmQIL43lec9n%2BlXlT3CkUzfvDdOnmCEoGzYuL2XB98D8vCZtSjSiQ5miKQG0btJj0ZTed%2Fu7YDSmOVzczTtfl&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20250409T081221Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTYQ7UEX4YT%2F20250409%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=b31d1c4ce03c5a0e65d9acbbb4ba3e02e1f4e8cb74135ecbe1c05c1f82e27ab6&hash=126ff7aa37c9aba4349e729aa2852e0bce9c260cfcd682dd4b6be08b541037c3&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S1361841524002822&tid=spdf-1ab78eed-e47c-41c4-bd24-bf008c8101d0&sid=6472ce05872ad34ab77a4da572218302f48dgxrqa&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&rh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=120d5956055b5f5b050654&rr=92d889fa3a448541&cc=hk&kca=eyJrZXkiOiJKOGorRnA4Tm13VGNqZjIwUmt6ajBDa1NndjdFNzczeGlzenRlbUVQenpiOC9IR3ZIQWFWU0p1aURGS3lMdjVBQXBrbXJaVmEveG8zKy9uUWFDNFlvQXMvdk1iSHY4WncrYmhFaklmOGVQQkh0MWRUVkhOWWdZM2ppV3V0L2xpd2ZMZWdHa1VYZy9TUWZhQlBRMzl4M3owQXFHSE0vS0pzVE14NmRDaTVaZ0hucGQ4ZSIsIml2IjoiZjhhMTk0MjkxZjVhMzFiZmRmYjQxOWNiMDQ0Yjg1NzIifQ==_1744186346729)  |
| 33    | KAD| Knowledge-enhanced visual-language pre-training on chest radiology images      | Medical       |[PDF](https://www.nature.com/articles/s41467-023-40260-7.pdf)  |
| 34    | LLaVA-Med| LLaVA-Med: Training a Large Language-and-Vision Assistant for Biomedicine in One Day      | Medical       |[PDF](https://proceedings.neurips.cc/paper_files/paper/2023/file/5abcdf8ecdcacba028c6662789194572-Paper-Datasets_and_Benchmarks.pdf)  |
| 35    | MedKLIP| MedKLIP: Medical Knowledge Enhanced Language-Image Pre-Training for X-ray Diagnosis      | Medical       |[PDF](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_MedKLIP_Medical_Knowledge_Enhanced_Language-Image_Pre-Training_for_X-ray_Diagnosis_ICCV_2023_paper.pdf)  |
| 36    | M-flag| M-FLAG: Medical Vision-Language Pre-training with Frozen Language Models and Latent Space Geometry Optimization      | Medical       |[PDF](https://arxiv.org/pdf/2307.08347)  |
| 37    | PMC-CLIP| PMC-CLIP: Contrastive Language-Image Pre-training using Biomedical Documents      | Medical       |[PDF](https://arxiv.org/pdf/2303.07240)  |
| 38    |PubMedCLIP| PubMedCLIP: How Much Does CLIP Benefit Visual Question Answering in the Medical Domain?      | Medical       |[PDF](https://aclanthology.org/2023.findings-eacl.88.pdf)  |
| 39    | Qilin-Med-VL| Qilin-Med-VL: Towards Chinese Large Vision-Language Model for General Healthcare      | Medical       |[PDF](https://arxiv.org/pdf/2310.17956)  |
| 40    | Ret-CLIP|RET-CLIP: A Retinal Image Foundation Model Pre-trained with Clinical Diagnostic Reports      | Medical       |[PDF](https://arxiv.org/pdf/2405.14137)  |
| 41    | BioMedLM| BioMedLM: A 2.7B Parameter Language Model Trained On Biomedical Text      | Medical       |[PDF](https://arxiv.org/pdf/2403.18421)  |
| 42    |CT-CLIP| Developing Generalist Foundation Models from a Multimodal Dataset for 3D Computed Tomography      | Medical       |[PDF](https://arxiv.org/pdf/2403.17834)  |
| 43    | Maco| Enhancing representation in radiography-reports foundation model: a granular alignment algorithm using masked contrastive learning      | Medical       |[PDF](https://www.nature.com/articles/s41467-024-51749-0.pdf)  |
| 44    | Medical X-VL| Self-supervised multi-modal training from uncurated images and reports enables monitoring AI in radiology      | Medical       |[PDF](https://pdf.sciencedirectassets.com/272154/1-s2.0-S1361841523X00073/1-s2.0-S1361841523002815/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEBAaCXVzLWVhc3QtMSJHMEUCIC3N0lwdWRhQDjL5jb1tf6uxNnNhAkzMMcx7Yy24D20XAiEAoThmKxs6EBhGIErYE3KoEhSiCMMVDTvsUSKR66xRS%2FEqvAUIif%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAFGgwwNTkwMDM1NDY4NjUiDJHdjTZV0t2TPi3nZiqQBXquKQy5EKEKEvrGVpR4euEHExWeYvms1TM2CQAr4CrI%2Fje9FYdBBSua6f4gw31UzPPxMB1i5A3RlUBg8ebPCfCfDNJ8AvxxyoVNdqU9BPalM7BIo5ey%2FqB1MEKilWVwrxHjcgAvNoKNyTjlaQs4XmEomSA6gAXRsmhWN8I3G%2BbYl8U7oL48JatKZTHNvkbU8zOlBwcenZHvG%2F4DmuPrsszzs%2BECcBnTfegWeT7EOvJ5oVng2%2B2zBQUwNrPR0HF%2FYtur0IjOqEAHxFYALS5w6AttN%2FUNuxu0017G7g7i1VR8Bc8OBOLP889enX%2FMx0e%2ByDg8qW9hCv4C0Kd7fTFaXsc7319pxaJikVnAMHGOf1pZFCnmyKI0n%2F5fHxTxdSb0rUuHJ04eYxpejrGweuvDBVn%2BUU9dYD2phR5%2FAtXvNbWQN%2Fhzbd0Ipa7Ae%2F1A7ae8%2FLNmiYHIHaaIiW7XhlY0zxxkSo%2Fvl5xWJbnlKkj8d4UaWOUKo2vQ5pnktpDCNhcCPKUG3%2BQyoTmxahqGIZUa720SN2dOK91y5TiV%2BUiRL26b9duObic2EJ%2BkPtpQzKKDvH8AJb%2B8%2FQ3vo5tA7PvpISee6deE3FG%2FlbhcbueXyC4pJg%2Bhxtpdic7FiV6t8BLT6a2oA%2FZ%2B6U2AK65Ehu4yzTDm4Peuw0%2FExs%2Bm%2BqIFmUNttIGXTLhC1rg6STMQV5pSeBfJyEV1YbjhuaI3ynTc1hFGF7KI%2B3vQYBll5YbXlNzDx4Yef7hcq0ib89v2g18vBK8Hcl3h0KHWx313bzWUdUEZCLxLhmUWobPZe4sB4ejqnZY8fLI9p1YFTRvkQoCi3xTNp1%2BcnKgKWMpYEpTqudVxLFyEpzhwzzHfRmlJd9kJMPHB2L8GOrEBwn2nt8h6N95CWhNPMv2c%2FqAGOiwJoelT0Wq1naGZwo7pA8l8n6QmUPE5Au45lixxlhM%2BXwqv05B%2Ftk4h3FvH4fQ%2Fm6oyH%2B%2BzGxbP6XOOmaW%2FlUJNnn9htlXAonY29ZwsnVAgjS3vr%2FHH73NxMGbJWQpKbtvcfHkvs27%2F5%2Bobt%2Bd%2BYvKlDJ8GBjUlTHJo9Zjmi%2FTHpcLhfsU0UfFGGN7Y9Rto%2BL8H7gGWHVYE21TloxAj&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20250409T082514Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTY7HQT7NEQ%2F20250409%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=73ddc4b2f47c5e850f7a23755fb0d64f32018e7f70bfaa7ae70ca6e14ccf4231&hash=bebc4805ae9fe726a754599d0d702205fc49f0b7f0f925ff4f9d50135805f76e&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S1361841523002815&tid=spdf-7163bf0a-cff2-496c-9c0f-352fd7db1d0e&sid=6472ce05872ad34ab77a4da572218302f48dgxrqa&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&rh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=120d5956055b5e01075001&rr=92d89cd7f8f80445&cc=hk)  |
| 45    | MPMA| Multi-Task Paired Masking With Alignment Modeling for Medical Vision-Language Pre-Training      | Medical       |[PDF](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10288259)  |
| 46    | QFT| Design as Desired: Utilizing Visual Question Answering for Multimodal Pre-training      | Medical       |[PDF](https://arxiv.org/pdf/2404.00226)  |
| 47    | Unichest| UniChest: Conquer-and-Divide Pre-Training for Multi-Source Chest X-Ray Classification      | Medical       |[PDF](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10478603)  |
| 48    |UniMed-CLIP| UniMed-CLIP: Towards a Unified Image-Text Pretraining Paradigm for Diverse Medical Imaging Modalities      | Medical       |[PDF](https://arxiv.org/pdf/2412.10372)  |


##Papers on Medical Report Generation using VLMs
---
| Index | Paper Names  | PDF Link       |
|:----:|:----------|:-----------|
| 1    | SERPENT-VLM: Self-Refining Radiology Report Generation Using Vision Language Models      |[PDF](https://arxiv.org/pdf/2404.17912)  |
| 2    | Kiut: Knowledge-injected u-transformer for radiology report generation      |[PDF](https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_KiUT_Knowledge-Injected_U-Transformer_for_Radiology_Report_Generation_CVPR_2023_paper.pdf)  |
| 3    | Token-Mixer: Bind Image and Text in One Embedding Space for Medical Image Reporting     |[PDF](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10552817)  |
| 4    | Medical-vlbert: Medical visual language bert for covid-19 ct report generation with alternate learning     |[PDF](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9509365)  |
| 5    | Medical Image Description Based on Multimodal Auxiliary Signals and Transformer      |[PDF](https://onlinelibrary.wiley.com/doi/pdf/10.1155/2024/6680546)  |
| 6    | Vision-knowledge fusion model for multi-domain medical report generation      |[PDF](https://pdf.sciencedirectassets.com/272144/1-s2.0-S1566253523X00050/1-s2.0-S1566253523001264/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEBIaCXVzLWVhc3QtMSJIMEYCIQDSD%2ByIxH0s6ijHnlJsZVmB%2Fu2AXROZ0Q0To69JiRAmpwIhAKc4uyJrhc7J482%2BzwHXY%2BPHyxbuQljpIuAGggOyAhKXKrsFCIr%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEQBRoMMDU5MDAzNTQ2ODY1Igx8eo%2Bh%2B%2B0p1LaTSXsqjwV84WaJgcoPyneMcmbrGsCCMWeMEXGFW290DQwzncXjcgAtr%2FS9VHeCRPnqXLy8RB1hIr97RMxTK7%2FOI2xGO81KJ5ArLKyPy42l2z%2Fkln6IkylbIF%2BpMbktCyFTiNZMqtydy6eOT%2FzoUyFlScvFVMPKuwe1tE0Z1WBZq0gptAj%2B%2BXkYJkmKmC9Zz6WkPp9gYXZ%2FtjALUattC0b69nfDv7vqhgtfzyZXBjJXvW2TjCuYtd%2BcUTPXVJAEtKB2%2Fd040dz8NMNKSmA9QjEfJBXSJrDu94ah%2F%2BWNZW03s8%2BOipnGrsfJCOILn%2FxxLZEuNX5A1JtV%2BkhqHKZQkaa86cxegr%2BHX%2Fe6YapxzPNt21q%2BpUYk8wFu8aBh9nhwr9f1O%2BQbb2zdJ2gb9jfY69XEFEOEtLoag%2Fo5trUiPvxHY7uKMKqlA%2BJlh%2BnbcwaqNkSJMnHKXZbkoCBkelpzz4w6FlUrv4GwX6gtIGM9zcCY19k%2BPQeRCX1mBOhBepLqR812M3qEjvAV8ny79K5THytcm%2Bl8J4qLvobCQmOHWRXXB%2BQhMNudcOgWOkKjN7DIus89IOPVAWgjfC%2FA3eW96n0Zt29755TjmerUchBhSP6vb5YF6ZdO%2BnFqcpXEHFxBTw6rzF%2FlYGgJWNmYFmrWRcxVsGiyvsEQ38dl3o1XnCvV0iYBccvGL2iUbrOvOvWu4%2B7Cr2BJrNldh96jOOp75Fuz18ybmcmbc6jD6VrIGNnlwPlhwShQuwNTa%2BFBEFiRPrmbmBtUjdwzqLOaMEie1DIOBiStKzA8HmlTI6QXp4Oqqn5UhtNkYWR0uY1C93lJEybplk%2BPwRTjOvKiUs3ECXNi%2FAKUSQJ%2BYimRi%2B0eMKp9HXCUXP78MNr22L8GOrABrObX7PO%2FcOyBgZjYv7lhaUiDxp8f81cNRxHvOkpkGuDSNmchdV3%2Fqu9z5grcJtkuCrFNaswu9GnMbFuNEMDQb%2FCQ%2FmS3blZrGXfU81QAlsJQhwXHHhjJECBirzZWbBuVhTaVobfkbC3D24CepmDFTJWwM%2FAIPBRKmb6WebuJGuWxZRlamSx8AEiyVJZgQfnCH9b%2B7zlU5jQByTGxrfnpEDTyverPWh8UvaqrxDm1TCk%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20250409T094817Z&X-Amz-SignedHeaders=host&X-Amz-Expires=299&X-Amz-Credential=ASIAQ3PHCVTYR4UVYR3S%2F20250409%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=4513b70fd854108e3a8b216c060f3adc51f4719cf94efeeb3506e9fc4e53cdfe&hash=f0d654ba525e6700da6645f6f2328cfc0fb992b9a17c6b8dbb22477a1bc0071c&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S1566253523001264&tid=spdf-c5e4a04f-87fd-4807-88ba-92675a888fa1&sid=6472ce05872ad34ab77a4da572218302f48dgxrqa&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&rh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=120d5956055a56545b5656&rr=92d9168119c884be&cc=hk&kca=eyJrZXkiOiJEaTdrWW5tOVdOd2lOUXhyVVN1VzdidmI0RGJpUnVGQXR6QXFFMWNYODdmZjlYNkJiMkUycEVDT2dJZjRDM1JOMlFFVmF4RWtnaDlqWXlMZWEwTDRwZzFCdXZzQ015QjRpVENsUnVnMHc5VEw5YUhHcXlObEkwUnFGaTJKcHUwMGNFZ04wR1FqcEF0a2U0V1dVSFZkOEg1ZmNnMDNiLzZkMDNCWCtQWHVYK2tBOEFjPSIsIml2IjoiNGUzNGQwODAzOGY0MTBkNDcxYzc3MzI2NGZkMDk5MjQifQ==_1744192102808)  |
| 7    | Automatic image and text-based description for colorectal polyps using BASIC classification      |[PDF](https://pdf.sciencedirectassets.com/271219/1-s2.0-S0933365721X00115/1-s2.0-S0933365721001718/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEBEaCXVzLWVhc3QtMSJGMEQCIESGdq%2FDa9rvL5PYnG4fcNpkngfzmXtMFE5HQ%2F4DWg1vAiBpLj%2Fsw4%2FbQJxr5XNF6pibt4rMMOOReW2fayGtAzm2XSq8BQiK%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAUaDDA1OTAwMzU0Njg2NSIMRAJeaPBTcxXD4HnvKpAF968bFQ28jTyyramY34Upapy5ZPCSQPVnquhEGoEjpypZ4%2F%2F0lwrSs8SH7Aa5GDr77d1CN%2FMY4SCBI4WXNhm4VJuAClme0qwsT5dZq0JrLQk4ULVjgfUKs76fKjnxNdgvULZ3P2SRpm3JJUUcCxgb9usK2NuJlQYrk5NZo3jM4WcCvnHvTG6MeQqdVPJ%2FfAjw8kfhzPcBXuObE2jo74xD0B4DjtWQbpWZ3WJjgDlWQBkTAJASGzSenq%2FgFJXSjWB1pPoE6b91SFVz0S6I9p356FmnGnq%2Bds53LFy2AhHVRK4IR0AMdyEU%2FC9tCoVhZHKl63Hu%2BKNtzhAsHTvieA1orTxZL7FHKiRMdXqj5dV6qzAfBv6qPAt%2FRUoTmoISfT%2Bjv8m2DhGKpk78Ta1eaMGC5sQ0gdkUfF7wYj6DE5swGegfnmta2iNQkxeWUI073bh%2BL2QMx8vUbNWQfRZEi31pzIWbTOyhtEjDSQZut6DOw5cBshXvfPOmOvTy70eYiltPfRvTJxhATtNhuDs%2F0QN3JfoEyjDbJckbQ%2B4FxO0IgFDd%2FK8OUq%2FuXkqMzvhQ3D%2BSB%2BPb5aJDh6sTjAt2k%2BhUla2wmxS7wxqNBle1Kq6OjkjNtX83pZ%2FKckhkytN8lLKAlFNodbiX7txKIrfAHRZ5Iiu9SQVa%2F0TBdVWTjkQkapyn1sQshR8xS8gELBQwiDdfU2%2BnOcSay5RMgQS8sSrXMarkn9ZP4KVZI1ggJ5MGGhhH3XVSIVmUALRXYyw2e2x36j%2Fqy2nXj1C7JxVgqooC7kxDa%2FU587IDHCobzNRxzRKBH8UN%2FxAUUhf7VWNQ1Xk2Y6Gt1RU3i6dUsCogm%2BEv0abIkFqtWF4ye4FA%2F%2F9Mgs8w5u7YvwY6sgGaXQrXSJunAN%2FM1mYYmIkxgqw1XmUWsmp4XoT%2FVY4f8ec8gPeaQuFaEbqtaDF5MQI7gyrBW8yoFNQbf0xknoBOBwaQokaNJVq7oRl7t%2BOcA0cMGVd9IJxkeMdPebxZi%2F%2FQoCaM9fOB89jVd8HWQhnlxvSyJmujeq0EywG3z0KFeRl41Y0DSlEE9ymxv3Q9fZCAn6pqhZFMnZefGtErMx5K1ay56bjrxqJYO8WeiTpEtMKM&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20250409T094850Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTY7AQD6ZFH%2F20250409%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=e838f088a3b5967bb888670beebc7a2a9e574b2ececc3bcb098b7939eb96b670&hash=8a1ca1f7005e141f23bdf14c22bcb2f3ddb7d51f6ca0f3105db9f4ea8086d425&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S0933365721001718&tid=spdf-65a3a3b8-1692-4c3d-a866-caf985e0b786&sid=6472ce05872ad34ab77a4da572218302f48dgxrqa&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&rh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=120d5956055a5655570153&rr=92d9174f480e84be&cc=hk)  |
| 8    | Improving Medical Speech-to-Text Accuracy using Vision-Language Pre-training Models     |[PDF](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10372102)  |
| 9    | Repsnet: Combining vision with language for automated medical reports     |[PDF](https://arxiv.org/pdf/2209.13171)  |
| 10    | Continually Tuning a Large Language Model for Multi-domain Radiology Report Generation      |[PDF](https://papers.miccai.org/miccai-2024/paper/0254_paper.pdf)  |
| 11    | Multimodal image-text matching improves retrieval-based chest x-ray report generation      |[PDF](https://proceedings.mlr.press/v227/jeong24a/jeong24a.pdf)  |
| 12    | Bootstrapping Large Language Models for Radiology Report Generation      |[PDF](https://ojs.aaai.org/index.php/AAAI/article/view/29826/31434)  |
| 13    | Clinical-Grade Multi-organ Pathology Report Generation for Multi-scale Whole Slide Images via a Semantically Guided Medical Text Foundation Model      |[PDF](https://arxiv.org/pdf/2409.15574)  |
| 14    | Contrastive learning with counterfactual explanations for radiology report generation      |[PDF](https://arxiv.org/pdf/2407.14474?)  |
| 15    | Pre-trained multimodal large language model enhances dermatological diagnosis using SkinGPT-4      |[PDF](https://www.nature.com/articles/s41467-024-50043-3.pdf)  |
| 16    | IQAGPT: computed tomography image quality assessment with vision-language and ChatGPT models     |[PDF](https://link.springer.com/content/pdf/10.1186/s42492-024-00171-w.pdf)  |

##Papers on Medical VQA using VLMs
---
| Index | Paper Names  | PDF Link       |
|:----:|:----------|:-----------|
| 17    | 项目A      |[PDF](https://google.com)  |
| 18    | 项目A      |[PDF](https://google.com)  |






























